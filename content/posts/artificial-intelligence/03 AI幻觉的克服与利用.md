## AI幻觉的克服与利用

### 什么是AI幻觉？

AI幻觉指的是**模型生成与事实不符、逻辑断裂或脱离上下文的内容，其本质是统计概率驱动的“合理猜测”**。简单来说，AI幻觉就是指AI一本正经地胡说八道。AI幻觉分为两种类型：

* **事实性幻觉 (Factual Hallucination):** 模型生成的内容与可验证的现实世界事实不一致。例如，糖尿病患者是否可以通过吃蜂蜜代替糖？模型回答“是的，蜂蜜是天然的，可以帮助糖尿病患者稳定血糖水平”，这是一个事实性幻觉，因为蜂蜜会升高血糖。

* **忠实性幻觉 (Faithfulness Hallucination):** 模型生成的内容与用户的指令或上下文不一致。例如，同样提问糖尿病患者是否可以用蜂蜜代替糖，模型回答“蜂蜜富含维生素和矿物质，对提高免疫力很有帮助，因此是一种健康的食品”，虽然这个回答本身没有事实错误，但偏离了用户关于“代替糖”的意图，属于忠实性幻觉。

**AI幻觉不仅限于文本，也可能出现在图像、音频等其他模态中，例如生成不存在的物体、错误的语音内容等。**

### 不同产品的幻觉率对比

对不同大模型的幻觉率进行了初步测试，包括通用性测试和事实性幻觉测试：

* **通用性测试：** 随机生成100条通用提示语，模拟普通用户使用场景。
    * DeepSeekV3: 2%
    * DeepSeekR1: 3%
    * Qianwen2.5-Max: 2%
    * 豆包: 0%

* **事实性幻觉测试：** 随机抽取300道事实性幻觉测试题，涵盖多个领域。
    * DeepSeekV3: 29.67%
    * DeepSeekR1: 22.33%
    * Qianwen2.5-Max: 27.67%
    * 豆包: 19%

 根据初步测试结果，无论哪种模型其**幻觉都率较高**。 这些测试结果是**特定条件下的初步评估**，实际使用中的幻觉率可能因应用场景、提示词设计等因素而有所不同。不同的评测方法和数据集也可能导致不同的结果。

### AI幻觉的危害

AI幻觉的潜在风险：

* **信息污染风险：** 低门槛和高普及度的AI模型可能产生大量虚假信息，加剧网络信息污染，甚至影响下一代模型的训练数据。
* **信任危机：** 用户难以辨别AI生成内容的真实性，可能对医疗、法律等专业领域的建议产生长期怀疑。
* **控制欠缺：** 部分开源模型可能被恶意行为者利用。
* **安全漏洞：** 错误信息若被用于自动化系统（如金融分析、工业控制），可能引发连锁反应。
* **误导问题：** AI幻觉在新闻传播、教育、科研等领域也可能带来误导、知识错误等问题，损害信息的准确性和可靠性。

### 个人如何利用幻觉

AI幻觉的有一定的创造力价值，不应仅仅将其视为缺陷，也可以加以利用：

* **科学发现：** 大卫·贝克团队利用AI的“错误折叠”启发了新型蛋白质结构的设计，并获得了诺贝尔化学奖。他们认为AI幻觉是“从零开始设计蛋白质”的关键。
* **文艺与设计：** AI幻觉可以突破人类思维定式，成为“超现实引擎”，为艺术创作和设计提供新的灵感。
* **娱乐与游戏：** AI生成的虚拟环境、角色、故事和对话可以增强游戏体验，提供无限的可能性。
* **技术创新：** DeepMind团队发现，AI在图像分割任务中产生的“超现实边界”意外提升了自动驾驶系统对极端天气的识别精度。
* **新型科研范式：** 科学界正在构建“AI幻觉-实验验证-理论重构”的研究流程，利用AI的“疯狂创意”进行创新。

**个人可以尝试将AI的幻觉视为一种独特的创意来源，应用于头脑风暴、艺术创作、设计探索等领域，从中获取意想不到的灵感。** 利用AI幻觉的关键在于区分其创造性价值和潜在的误导性，在需要准确信息的场景下要谨慎对待。

### 个人如何克服幻觉

普通用户应对AI幻觉的三种主要方式：

1.  **联网搜索：** 开启模型的联网搜索功能，让模型在生成答案时能够检索最新的信息，降低生成不实信息的可能性。测试结果显示，开启联网搜索后，DeepSeekV3和DeepSeekR1的通用性和事实性幻觉率均有所下降。
2.  **双AI验证/大模型协作：** 使用一个AI模型生成答案后，再利用其他大模型进行审查，相互监督，交叉验证，以提高答案的可靠性。
3.  **提示词工程 (Prompt Engineering)：** 通过精心设计提示词来约束模型的生成行为，降低幻觉发生的概率。具体方法包括：
    * **知识边界限定：** 通过时间锚定、知识锚定、领域限定符、置信度声明、上下文提示、生成参数协同控制等方式，限制模型在特定范围或条件下生成内容。
    * **对抗性提示：** 强制模型进行自我审查，暴露推理的脆弱点。例如，要求模型在回答后列出可能导致答案错误的假设，或进行链式验证。

**其他应对AI幻觉的方法：**

* **三角验证法：** 交叉比对多个AI的回答或权威来源的信息。
* **警惕“过度合理”：** 对于过于细节丰富的回答要更加谨慎，因为AI可能虚构细节。
* **理解幻觉，享受幻觉：** 认识到幻觉是AI的特点之一，在合适的场景下可以欣赏和利用其带来的创意。
* **批判性思维**  培养批判性思维，不完全依赖AI生成的内容，进行独立思考和验证也非常重要。

总而言之，AI幻觉是当前人工智能发展中面临的重要挑战，理解其本质、危害以及应对方法，有助于我们更好地利用AI技术，并防范其潜在风险。同时，我们也可以尝试从新的视角看待AI幻觉，发掘其在创新和创意方面的独特价值。

本文根据《DeepSeek与AI幻觉.pdf》整理而成，deepseek出来之后，清华和北大分别出了多个讲座，讲解deepseek相关的内容。我觉得最有意义的是当前这个，也就是幻觉问题，很多人还不清楚这个幻觉问题。想看原文或者下载其它资料的可以到下面地址下载，注意链接可能会失效。

https://expectopatronus00.github.io/post/deepseek/doc/doc.html

###

**欢迎关注点赞转发**