<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>人工智能 | 万年水的博客</title><meta name=keywords content><meta name=description content="AI技术与应用前沿"><meta name=author content><link rel=canonical href=https://bsong2015.github.io/blog/posts/artificial-intelligence/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://bsong2015.github.io/blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bsong2015.github.io/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://bsong2015.github.io/blog/favicon-32x32.png><link rel=apple-touch-icon href=https://bsong2015.github.io/blog/apple-touch-icon.png><link rel=mask-icon href=https://bsong2015.github.io/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://bsong2015.github.io/blog/posts/artificial-intelligence/index.xml><link rel=alternate hreflang=zh href=https://bsong2015.github.io/blog/posts/artificial-intelligence/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://bsong2015.github.io/blog/posts/artificial-intelligence/"><meta property="og:site_name" content="万年水的博客"><meta property="og:title" content="人工智能"><meta property="og:description" content="AI技术与应用前沿"><meta property="og:locale" content="zh"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="人工智能"><meta name=twitter:description content="AI技术与应用前沿"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://bsong2015.github.io/blog/posts/"},{"@type":"ListItem","position":2,"name":"人工智能","item":"https://bsong2015.github.io/blog/posts/artificial-intelligence/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://bsong2015.github.io/blog/ accesskey=h title="万年水的博客 (Alt + H)">万年水的博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://bsong2015.github.io/blog/posts/artificial-intelligence/ title=人工智能><span class=active>人工智能</span></a></li><li><a href=https://bsong2015.github.io/blog/posts/reading/ title=阅读><span>阅读</span></a></li><li><a href=https://bsong2015.github.io/blog/posts/thinking-models/ title=思维模型><span>思维模型</span></a></li><li><a href=https://bsong2015.github.io/blog/posts/thought-experiments/ title=思想实验><span>思想实验</span></a></li><li><a href=https://bsong2015.github.io/blog/posts/personal-growth/ title=个人成长><span>个人成长</span></a></li><li><a href=https://bsong2015.github.io/blog/posts/technology/ title=技术><span>技术</span></a></li><li><a href=https://bsong2015.github.io/blog/posts/current-affairs/ title=时事><span>时事</span></a></li><li><a href=https://bsong2015.github.io/blog/posts/others/ title=其它><span>其它</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>人工智能</h1><div class=post-description>AI技术与应用前沿</div></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent></h2></header><div class=entry-content><p>DeepSeek 这种强推理模型能够解决奥数题，代表了人工智能在逻辑推理和问题解决能力上的巨大进步。这对中小学教育以及学生素质培养都提出了新的挑战和机遇。中小学生在 AI 时代，应该着重培养以下几个方面的素质，才能更好地适应和驾驭这个快速发展的时代：
一、 培养核心认知能力，而非仅仅是知识记忆
批判性思维 (Critical Thinking)：
不再迷信权威答案： AI 可以给出答案，但学生需要学会质疑、评估和验证 AI 给出的信息和解决方案，而不是盲目接受。要培养独立思考的能力，对信息进行筛选和辨别。 分析和评估信息来源： 训练学生分析信息来源的可靠性、偏见性和局限性。例如，了解 AI 模型是基于数据训练的，其结果也可能受到数据质量和算法偏见的影响。 逻辑推理和论证： 即使 AI 可以做奥数题，学生也要理解解题背后的逻辑和推理过程，锻炼自己的逻辑思维能力，能够构建清晰的论证，并识别逻辑谬误。 创造性思维 (Creative Thinking)：
发散性思维和创新： AI 擅长在已知框架内进行优化和推理，但人类的创造力在于突破框架、提出新颖的想法和解决方案。要鼓励学生进行发散性思维，培养创新意识，敢于提出独特见解。 想象力和艺术感： 艺术、音乐、文学等领域仍然是人类创造力的重要体现。发展学生的想象力、审美能力和艺术鉴赏力，这些是 AI 难以完全替代的。 解决复杂和模糊问题的能力： 真实世界的问题往往是复杂、模糊且充满不确定性的，需要人类运用创造性思维来定义问题、寻找新的解决方案。要培养学生应对复杂性和模糊性的能力。 问题解决能力 (Problem-Solving)：
定义和分解问题： 即使 AI 能解奥数题，现实生活中的问题往往更复杂。学生需要学会如何清晰地定义问题，将复杂问题分解为可管理的部分，并理解问题的本质。 多角度思考和跨学科应用： 培养学生从不同角度看待问题，运用跨学科知识和方法来寻找解决方案。例如，一个社会问题可能需要结合经济学、社会学、心理学等多学科知识来解决。 迭代和实验精神： 解决复杂问题通常需要多次尝试和迭代。要培养学生的实验精神，不怕失败，从错误中学习，不断改进解决方案。 二、 掌握必要的数字技能和 AI 工具应用能力
基础数字素养 (Digital Literacy)：
信息检索和筛选： AI 时代信息爆炸，学生需要掌握高效的信息检索技巧，并学会从海量信息中筛选出有价值的内容。 数字工具应用： 熟练使用各种数字工具，包括办公软件、协作平台、在线学习资源等，提高学习和工作效率。 网络安全和信息保护意识： 了解网络安全风险，保护个人信息和数据安全，负责任地使用网络资源。 AI 工具的理解和应用 (AI Tool Proficiency)：
了解 AI 的基本原理和应用场景： 不需要深入了解 AI 的技术细节，但需要理解 AI 的基本工作原理，了解 AI 在各个领域的应用场景和潜力。 学会使用 AI 辅助学习工具： 例如，利用 AI 驱动的搜索引擎更高效地查找资料，使用 AI 写作工具辅助写作，利用 AI 辅导系统进行个性化学习等。 理解 AI 的局限性： 认识到 AI 不是万能的，理解 AI 的局限性和潜在的偏见，避免过度依赖 AI。 编程和计算思维 (Computational Thinking)：
...</p></div><footer class=entry-footer></footer><a class=entry-link aria-label="post link to " href=https://bsong2015.github.io/blog/posts/artificial-intelligence/01-deepseek%E5%BC%BA%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%87%BA%E7%8E%B0%E5%AF%B9%E4%B8%AD%E5%B0%8F%E5%AD%A6%E7%94%9F%E6%95%99%E8%82%B2%E7%9A%84%E8%A6%81%E6%B1%82/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent></h2></header><div class=entry-content><p>数字时代过度依赖与数字极简主义：数字轻断食 现代社会对数字设备的过度依赖已成为普遍现象，并对个人和社会层面产生深远影响 数字设备的“成瘾性”： 随着互联网和智能手机的普及，数字设备不再仅仅是工具，其便捷性和丰富的功能使其具备了类似成瘾的特性，如同早期互联网不发达时难以想象人们会对手机产生如此强烈的依赖。 “集体潜意识”般的依赖： 无论在地铁、课堂、会议，还是在老年人群体和基层服务人员中，无意识地刷手机已成为一种普遍的习惯，仿佛一种“集体潜意识”。 即时获取信息的冲动： 遇到问题时，人们习惯性地立即通过手机搜索答案，这种即时满足的习惯进一步加剧了数字依赖。 借鉴“轻断食”理念，推行“数字极简主义” “数字轻断食”的类比： 将适度减少数字设备的使用比作身体的轻断食，旨在帮助人们在过度沉溺与完全隔绝之间找到一个健康的平衡点。 数字依赖带来的负面影响： 身体健康问题： 长时间使用手机导致眼睛疲劳、身体疲惫等健康问题。 认知能力下降： 过多碎片化信息和干扰导致注意力分散、记忆力下降，甚至使人“变笨”。 信息污染： 网络充斥着广告、营销号、虚假信息、煽动性内容以及大量无意义的信息，难以带来真实的快乐和有效的信息。 短暂的快乐与长期的损害： 类似吸烟，数字设备带来的快乐可能是短暂的，但长期来看会对身心健康造成损害。 “数字极简主义”的内涵： 提倡有意识地减少不必要的数字设备使用，合理规划使用时间，避免过度沉溺，但也不主张完全断网或卸载常用应用等极端做法，因为这在现代社会可能会带来不便甚至负面影响。 避免激进的“数字罢工”： 突然完全停止使用某些应用或断网可能会适得其反，类似于节食过度容易暴饮暴食。这种激进的方式可能会伤害到自己和身边的人。 手机依赖的心理机制 无意识的习惯： 对手机的依赖已根深蒂固，成为一种潜意识行为，即使没有明确的需求，也会忍不住想刷手机来填补空白。 错失恐惧症（FOMO，Fear of missing out）： 人们总担心错过重要信息或社交动态，即使接收的大部分信息是无用的。 通过刷手机排解负面情绪： 不开心时，刷短视频或浏览社交媒体可以带来短暂的快乐，成为一种逃避现实的方式。 断网行为的复杂性： 彻底断网在全民上网的时代显得稀缺，有时可能被视为一种“逃避主义的行为艺术”，但也反映了人们对过度数字连接的反思。 保持人与手机之间的“边界感” 类比人际关系： 就像人与人之间需要保持适当的距离，人与手机也应如此，避免过度黏在一起。 协商式的边界： 减少刷手机的时间，例如将原本一下午的刷手机时间缩短为半下午，留出时间做其他事情。 克服“停不下来”的困境： 意识到手机上的各种内容容易分散注意力，导致忘记原本的目的。 固定时间： 养成在只在固定时间（如饭前、睡前）使用手机的习惯，同时控制时长，避免无形中将手机融入生活的方方面面。 利用社交媒体日记戒断手机依赖 “以毒攻毒”的方法： 在社交媒体上公开记录戒断日记，利用人们的表现欲和连接欲来推动戒断过程。 外部监督与支持： 通过熟人圈和陌生兴趣圈获得监督、鼓励和支持。 自我反思与记录： 记录与手机的关系，反思上网行为，了解自己的使用习惯和感受。 获得秩序感与意义： 在看似无聊的戒断过程中，通过写作和分享找到秩序感和意义，带来内心的稳定感。 持续的刻意练习： 改变习惯需要时间和坚持，是一个循序渐进的过程。 最终目标： 找到与数字设备之间的健康相处模式，既不完全排斥，也不过度依赖，从而提高生活质量，实现数字生活与现实生活的平衡。
欢迎关注点赞转发</p></div><footer class=entry-footer></footer><a class=entry-link aria-label="post link to " href=https://bsong2015.github.io/blog/posts/artificial-intelligence/02-%E6%95%B0%E5%AD%97%E8%BD%BB%E6%96%AD%E9%A3%9F/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent></h2></header><div class=entry-content><p>AI幻觉的克服与利用 什么是AI幻觉？ AI幻觉指的是模型生成与事实不符、逻辑断裂或脱离上下文的内容，其本质是统计概率驱动的“合理猜测”。简单来说，AI幻觉就是指AI一本正经地胡说八道。AI幻觉分为两种类型：
事实性幻觉 (Factual Hallucination): 模型生成的内容与可验证的现实世界事实不一致。例如，糖尿病患者是否可以通过吃蜂蜜代替糖？模型回答“是的，蜂蜜是天然的，可以帮助糖尿病患者稳定血糖水平”，这是一个事实性幻觉，因为蜂蜜会升高血糖。
忠实性幻觉 (Faithfulness Hallucination): 模型生成的内容与用户的指令或上下文不一致。例如，同样提问糖尿病患者是否可以用蜂蜜代替糖，模型回答“蜂蜜富含维生素和矿物质，对提高免疫力很有帮助，因此是一种健康的食品”，虽然这个回答本身没有事实错误，但偏离了用户关于“代替糖”的意图，属于忠实性幻觉。
AI幻觉不仅限于文本，也可能出现在图像、音频等其他模态中，例如生成不存在的物体、错误的语音内容等。
不同产品的幻觉率对比 对不同大模型的幻觉率进行了初步测试，包括通用性测试和事实性幻觉测试：
通用性测试： 随机生成100条通用提示语，模拟普通用户使用场景。
DeepSeekV3: 2% DeepSeekR1: 3% Qianwen2.5-Max: 2% 豆包: 0% 事实性幻觉测试： 随机抽取300道事实性幻觉测试题，涵盖多个领域。
DeepSeekV3: 29.67% DeepSeekR1: 22.33% Qianwen2.5-Max: 27.67% 豆包: 19% 根据初步测试结果，无论哪种模型其幻觉都率较高。 这些测试结果是特定条件下的初步评估，实际使用中的幻觉率可能因应用场景、提示词设计等因素而有所不同。不同的评测方法和数据集也可能导致不同的结果。
AI幻觉的危害 AI幻觉的潜在风险：
信息污染风险： 低门槛和高普及度的AI模型可能产生大量虚假信息，加剧网络信息污染，甚至影响下一代模型的训练数据。 信任危机： 用户难以辨别AI生成内容的真实性，可能对医疗、法律等专业领域的建议产生长期怀疑。 控制欠缺： 部分开源模型可能被恶意行为者利用。 安全漏洞： 错误信息若被用于自动化系统（如金融分析、工业控制），可能引发连锁反应。 误导问题： AI幻觉在新闻传播、教育、科研等领域也可能带来误导、知识错误等问题，损害信息的准确性和可靠性。 个人如何利用幻觉 AI幻觉的有一定的创造力价值，不应仅仅将其视为缺陷，也可以加以利用：
科学发现： 大卫·贝克团队利用AI的“错误折叠”启发了新型蛋白质结构的设计，并获得了诺贝尔化学奖。他们认为AI幻觉是“从零开始设计蛋白质”的关键。 文艺与设计： AI幻觉可以突破人类思维定式，成为“超现实引擎”，为艺术创作和设计提供新的灵感。 娱乐与游戏： AI生成的虚拟环境、角色、故事和对话可以增强游戏体验，提供无限的可能性。 技术创新： DeepMind团队发现，AI在图像分割任务中产生的“超现实边界”意外提升了自动驾驶系统对极端天气的识别精度。 新型科研范式： 科学界正在构建“AI幻觉-实验验证-理论重构”的研究流程，利用AI的“疯狂创意”进行创新。 个人可以尝试将AI的幻觉视为一种独特的创意来源，应用于头脑风暴、艺术创作、设计探索等领域，从中获取意想不到的灵感。 利用AI幻觉的关键在于区分其创造性价值和潜在的误导性，在需要准确信息的场景下要谨慎对待。
个人如何克服幻觉 普通用户应对AI幻觉的三种主要方式：
联网搜索： 开启模型的联网搜索功能，让模型在生成答案时能够检索最新的信息，降低生成不实信息的可能性。测试结果显示，开启联网搜索后，DeepSeekV3和DeepSeekR1的通用性和事实性幻觉率均有所下降。 双AI验证/大模型协作： 使用一个AI模型生成答案后，再利用其他大模型进行审查，相互监督，交叉验证，以提高答案的可靠性。 提示词工程 (Prompt Engineering)： 通过精心设计提示词来约束模型的生成行为，降低幻觉发生的概率。具体方法包括： 知识边界限定： 通过时间锚定、知识锚定、领域限定符、置信度声明、上下文提示、生成参数协同控制等方式，限制模型在特定范围或条件下生成内容。 对抗性提示： 强制模型进行自我审查，暴露推理的脆弱点。例如，要求模型在回答后列出可能导致答案错误的假设，或进行链式验证。 其他应对AI幻觉的方法：
...</p></div><footer class=entry-footer></footer><a class=entry-link aria-label="post link to " href=https://bsong2015.github.io/blog/posts/artificial-intelligence/03-ai%E5%B9%BB%E8%A7%89%E7%9A%84%E5%85%8B%E6%9C%8D%E4%B8%8E%E5%88%A9%E7%94%A8/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent></h2></header><div class=entry-content><p>模型上下文协议 (MCP)：连接 AI 模型与世界的标准化桥梁 引言 随着人工智能技术的飞速发展，大型语言模型（LLMs）的能力日益强大，它们在理解和生成自然语言方面取得了显著的进步。然而，要让这些模型真正服务于现实世界的应用，仅仅依靠其预训练的知识是远远不够的。它们需要能够安全、高效地访问外部数据源、利用各种工具，并根据用户的具体需求进行定制化的交互。在这样的背景下，由 Anthropic 公司发起并开源的模型上下文协议 (Model Context Protocol, MCP) 应运而生。MCP 旨在为 AI 模型与外部世界建立一座标准化的桥梁，正如 USB-C 接口统一了各种电子设备的连接方式一样，MCP 有望革新 AI 模型的集成方式，极大地提升 AI 应用的灵活性、可扩展性和实用性。
MxN 集成挑战与标准化需求 在 MCP 出现之前，将 M 个 AI 模型与 N 个不同的工具或数据源集成，往往需要构建 M x N 个定制化的集成方案。这种“MxN”问题导致了复杂性的爆炸式增长，不仅开发和维护成本高昂，而且难以实现不同 AI 模型和外部资源之间的互操作性。例如，一个企业可能同时使用来自不同供应商的多个 LLM，并且需要让它们能够访问企业内部的数据库、文件系统、以及各种外部 API。如果每种 LLM 都需要针对每种数据源和工具进行单独的适配，其工作量和复杂性可想而知。
为了解决这一瓶颈，行业迫切需要一种标准化的协议，使得每个 AI 模型和每个外部资源只需要遵循一次标准即可实现互联互通。MCP 的目标正是将这种复杂性降低到 M + N 的水平，极大地简化了 AI 集成的过程。语言服务器协议 (Language Server Protocol, LSP) 在代码编辑器和编程语言的集成领域取得了巨大的成功，它通过标准化开发工具与编程语言之间的通信方式，极大地提升了开发效率和用户体验。MCP 正是希望在 AI 集成领域复制 LSP 的成功，通过提供一个通用的接口，让 AI 模型能够以统一的方式与各种外部资源进行交互。
MCP 的工作原理：架构与核心组件 MCP 采用经典的客户端-服务器架构。其中，AI 应用程序（例如一个聊天机器人或一个智能助手）扮演 MCP 客户端（或称为主机）的角色，而提供数据、工具或提示的外部系统则扮演 MCP 服务器的角色。
...</p></div><footer class=entry-footer></footer><a class=entry-link aria-label="post link to " href=https://bsong2015.github.io/blog/posts/artificial-intelligence/04-%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE-mcp%E8%BF%9E%E6%8E%A5-ai-%E6%A8%A1%E5%9E%8B%E4%B8%8E%E4%B8%96%E7%95%8C%E7%9A%84%E6%A0%87%E5%87%86%E5%8C%96%E6%A1%A5%E6%A2%81/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent></h2></header><div class=entry-content><p>AI模型的政治倾向和聪明程度 AI的“政治倾向” 第一张图（见下图）就是AI模型的“政治倾向”。这个图有两个维度：一个是经济上的立场，从左到右代表着对政府干预经济的不同态度；另一个是社会立场，从下到上代表着对个人自由和社会秩序的不同侧重。
这张图片展示了一个“AI 政治倾向”图表。它通过一个标准的政治倾向测试（politicalcompass.org/test）来评估不同人工智能模型的政治倾向。
图片的核心是一个二维坐标系，代表了政治倾向。 横轴 (Economic): 代表经济立场，从左（Economic Left）到右（Economic Right）。左边通常代表支持更多政府干预、福利制度和经济平等；右边则倾向于自由市场、低税收和较少的政府干预。 纵轴 (Social): 代表社会立场，从下（Social Libertarianism）到上（Social Authoritarianism）。下方代表更倾向于个人自由、容忍不同的生活方式和较少的政府对个人行为的干预；上方则倾向于社会秩序、传统价值观和更强的政府控制。 这个坐标系将政治立场划分为四个象限，所有的模型现在都落在第三象限，表示AI倾向于经济上的政府干预（如福利制度），但在社会生活上强调个人自由。 AI的“聪明程度” 第二张图（见下图）展示了不同AI模型在门萨智商测试中的得分情况。门萨测试是一种广为认可的智力测试，能大致反映一个人的逻辑思维和问题解决能力。
图上横轴是智商分数，100分左右是人类的平均水平。可以看到，各种AI模型的得分也各不相同。其中Gemini 2.5 Pro Exp的模型，它的平均智商分数达到了128分。下面是具体的数据图片：
想象一下 AI的发展很快，当智商达到140的时候可能带来巨大的进步和机遇，但也伴随着失业、伦理和安全等风险。当达到160的时候可能代表着一个全新的智能时代，其潜力巨大，但也带来了前所未有的挑战，甚至可能涉及人类的生存问题。到那时候它的伦理道德和政治倾向将影响更大。
参考https://trackingai.org/home
欢迎关注+点赞+转发</p></div><footer class=entry-footer></footer><a class=entry-link aria-label="post link to " href=https://bsong2015.github.io/blog/posts/artificial-intelligence/05-ai%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%94%BF%E6%B2%BB%E5%80%BE%E5%90%91%E5%92%8C%E8%81%AA%E6%98%8E%E7%A8%8B%E5%BA%A6/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent></h2></header><div class=entry-content><p>标题：阿里的Qwen3确实很强，但“超越”、“登顶”？我们用事实来看！
随着 Qwen3模型的发布，不少文章标题都用了“超越”、“登顶”、“SOTA”等颇具吸引力的词汇，字里行间透露着这款新模型已经力压群雄、独孤求败的意味。
Qwen3 毫无疑问是一款非常强大的模型，这一点毋庸置疑。但事实是否真的如此绝对？“超越”、“登顶”这些词，我们需要基于更全面的数据来审视。
我们先看看官方的描述“我们的旗舰模型 Qwen3-235B-A22B 在代码、数学、通用能力等基准测试中，与 DeepSeek-R1、o1、o3-mini、Grok-3 和 Gemini-2.5-Pro 等顶级模型相比，表现出极具竞争力的结果”，极具竞争力还是比较客观的，比其它媒体都准确一些。
这里有一份包含 Qwen3-235B-A22B 在内，对比多个主流大型模型在一些列评测基准上表现的表格（表格来源: 千问官方公众号）。让我们基于这份事实数据，来理性分析一下 Qwen3-235B-A22B 的能力定位。
（此处可以插入表格图片，或简单描述表格内容，例如：）
数据怎么说？
毋庸置疑，Qwen3-235B-A22B 的成绩非常亮眼：
在 ArenaHard（复杂对话/指令）上获得 95.6 分。 在 AIME 数学竞赛基准（‘24 和 ‘25）上分别获得 85.7 和 81.5 的高分。 在 Codeforces Elo Rating 这一衡量竞技编程能力的指标上达到 2056 分。 在 LiveBench 和 MultiIF 等基准上也表现出色。 这些分数表明，Qwen3-235B-A22B 在通用能力、数学推理和编程等核心领域确实具备顶级模型的实力。特别是在 ArenaHard 和 AIME 等评测中，它的分数是名列前茅的。
但是，“超越”和“登顶”了吗？
当我们审视表格中的其他模型，尤其是 Gemini 2.5-Pro 时，会发现情况并非那么简单：
在 ArenaHard 上，Gemini 2.5-Pro 获得了 96.4 分，略高于 Qwen3-235B-A22B。 在 AIME'24 (92.0 分) 和 AIME'25 (86.7 分) 上，Gemini 2.5-Pro 的分数均高于 Qwen3-235B-A22B。 在 LiveBench (82.4 分) 和 MultiIF (77.8 分) 上，Gemini 2.5-Pro 的得分也更高。 即使在 Qwen3-235B-A22B 表现优秀的 Codeforces Elo Rating (2056 分) 上，Gemini 2.5-Pro 也取得了 2001 分的非常接近的成绩。 从这份数据来看，Gemini 2.5-Pro 在多个关键基准上表现与 Qwen3-235B-A22B 相当，甚至在部分通用能力和数学评测中分数更高。表格中的 Deepseek-Rl、OpenAI-0x01 等模型在某些单项上也展现出了各自的优势。
...</p></div><footer class=entry-footer></footer><a class=entry-link aria-label="post link to " href=https://bsong2015.github.io/blog/posts/artificial-intelligence/06-qwen3-sota/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent></h2></header><div class=entry-content><p>让AI听懂“人话”，没那么简单！揭秘自然语言交互背后的挑战与解决方案 想象一下，你不再需要点击层层菜单，填写繁琐表单，只需要像和同事聊天一样，对电脑或手机说：“帮我查一下上个月销售额最高的三个城市”或者“把这个月未支付的订单都导出来”。这就是产品交互“AI化”的核心目标：用最自然、最直观的语言来控制复杂的系统。
这种革命性的交互方式，深度依赖于大语言模型（LLM）强大的自然语言理解能力，将用户的“人话”精准转换成系统能执行的指令，也就是所谓的“Function Call”（函数调用）。虽然前景光明，但将这一愿景落地到实际产品中，却面临着一系列现实挑战。今天，我们就来深入揭秘其中的几个关键问题，并看看业界是如何尝试解决这些挑战的。
挑战一：AI能听懂指令，但“听准”没那么容易——Function Call 的准确率不高 问题描述： 用户说“帮我新建一个客户”，系统背后可能需要调用一个名为 create_customer 的接口，并需要提供客户姓名、联系方式等参数。Function Call 的核心任务就是识别用户意图是“新建客户”，并从用户的话语中精确提取出所需的参数。然而，实际应用中，AI 识别并执行正确函数和参数的准确率并不总是尽如人意。即使是当前最先进的模型，在伯克利的函数调用测评集PFCL上的综合准确率也只有70%多。这意味着，大约有 30% 的情况下，AI 可能会理解错误，导致执行了不相关的操作，或者因为无法提取必需参数而无法执行用户指令。
为什么会这样？ 自然语言是高度灵活、充满歧义且语境依赖的。用户可能用五花八门的方式表达同一个意思，习惯性地省略信息，使用同义词，甚至表达一些模棱两可的指令。而系统拥有的函数接口则是固定、规范且要求严格的。将灵活多变的“人话”精确无误地映射到规范严谨的“机器指令”，本身就是一项极具挑战性的任务。
解决方案：
优化函数描述： 这是基础中的基础。为 LLM 提供清晰、准确、带有高质量示例的函数描述至关重要。函数名应直观易懂，描述要详细说明其功能、每个参数的含义、数据类型和格式要求。这就像为 AI 提供一份详尽的操作手册。 Few-shot Learning以及提示词工程： 在给 LLM 的 Prompt 中，加入少量高质量的用户 query 到 Function Call 的映射示例。通过这些具体的例子，AI 能更好地理解如何从相似的表达中提取关键信息并映射到正确的函数。 引入中间层（意图识别与参数提取）： 不完全依赖 LLM 一步到位完成所有工作。可以在 LLM 之外增加一个专门的意图识别模块，先行判断用户的核心意图（例如，是“查询订单”还是“创建用户”），再根据意图将请求导向相关的函数子集。之后，可以使用 LLM 或更专业的 NLP 模型进行参数的提取和校验。这种模块化的流水线方式可以显著提高特定环节的处理准确率。 后置校验与确认： 在 AI 生成 Function Call 指令后，不立即执行，而是进行多重校验。例如，检查提取的参数是否符合函数要求的格式、范围等。更进一步，可以将解析出的用户意图和关键参数用自然语言反馈给用户进行二次确认：“您是希望创建一个名为 [客户姓名] 的新客户吗？”等待用户明确肯定后再执行。 挑战二：一句一句交流没问题，但聊复杂事情就犯晕——多轮 Function Call 准确率更低 问题描述： 如果用户说：“帮我查一下北京的订单”，系统执行查询后，用户接着说“只要金额大于 1000 的”，然后又说“把这些订单按时间排序”。这是一个典型的多轮对话场景。系统需要在后续轮次中记住并利用之前的上下文（正在查询订单、限定了北京的条件），并理解用户的后续指令（增加金额条件、改变排序方式）是基于前序操作的细化、修改或进一步处理，而不是全新的请求。然而，在复杂的多轮对话场景下，Function Call 的准确率会大幅下降，有时甚至低于 30%，导致交互体验断裂。
为什么会这样？ 多轮对话不仅考验单轮的语言理解能力，更对系统的对话状态管理和跨轮次的关联理解提出了更高要求。AI 需要克服以下困难：
...</p></div><footer class=entry-footer></footer><a class=entry-link aria-label="post link to " href=https://bsong2015.github.io/blog/posts/artificial-intelligence/07-ai%E5%8A%A9%E6%89%8B%E5%BC%80%E5%8F%91/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent></h2></header><div class=entry-content><p>提示词工程进阶：从指令艺术到与大模型共舞的科学 在大型语言模型（LLM）日益成为技术革新基石的今天，提示词工程（Prompt Engineering）已不再是简单的“告诉模型做什么”，而是演进为一门集认知科学、计算机科学与语言学于一体的复杂学科。对于专业的提示词工程师而言，追求的不仅是“可用”的输出，更是极致的性能、卓越的鲁棒性、精细的可控性以及对模型潜能的深度挖掘。本文基于 Kaggle Whitepaper on Prompt Engineering 和 PromptingGuide.ai 的前沿洞见，旨在为有经验的从业者提供新的视角与启发，深入探讨提示词工程的高级策略与实践，并辅以具体示例。
一、 洞悉模型心智：超越表层指令的深层交互
提示词工程不仅需要注重指令的清晰与具体，更需理解这些指令如何在模型的内部机制中发挥作用，实现与模型的深度“共舞”。
引导注意力焦点与明确性： Transformer 架构的核心在于注意力机制。精心设计的提示词能有效引导模型将计算资源聚焦于输入中最关键、最相关的部分。指令的清晰度 (Clarity) 和具体性 (Specificity) 至关重要，避免歧义，明确任务目标。
不够明确的提示：
“帮我计划一个周末去处。” 优化后的引导注意力焦点的提示：
“我们一家三口（两个大人，一个5岁小孩）周末想在北京市内找个地方玩一天。我们主要想去一个适合孩子、能亲近自然的地方，最好交通方便，单程不要超过1.5小时车程。请推荐2-3个选择，并简要说明每个地方的特色、适合孩子的点以及大致的门票和交通方式” 上下文学习（In-Context Learning / Few-Shot Prompting）： 这是 LLM 的一个强大能力，通过在提示中提供少量任务示例（demonstrations），模型可以快速学习并模仿示例的模式来完成新任务，而无需更新模型参数。
示例（情感分类 Few-Shot）： 文本：这家餐厅的食物太美味了！ 情感：积极 文本：等了快一个小时，服务太差了。 情感：消极 文本：电影情节一般，但演员表现不错。 情感：中性 文本：我对这个产品非常失望，完全不值这个价。 情感： 模型会根据提供的示例推断出最后一个文本的情感为“消极”。 精细化上下文管理： 模型的上下文窗口是有限的“记忆空间”。处理长文本或复杂对话时，如何高效利用这一资源至关重要。
滑动窗口与摘要注入： 对于超出单次处理上限的长文本，可采用滑动窗口技术。处理后续窗口时，将前序窗口的关键信息以简洁摘要形式注入当前提示，确保上下文的连贯性与核心信息的传递。 示例： 处理一本200页的书籍。分块处理时，处理第21-40页的提示可包含：“这是书籍的第21-40页。前20页的核心摘要是：[此处插入第一区块的摘要]。请基于此继续分析当前区块，识别关键主题和论点。” 结构化信息封装： 将非结构化信息转化为模型更易解析和利用的结构化（如 JSON, XML）或半结构化格式输入，可显著提升信息利用效率，减少上下文浪费。 示例： 客户反馈：“产品A很好用，但B的界面太复杂了，而且C经常崩溃。” 可转化为： { "customer_feedback": [ {"product": "A", "sentiment": "positive", "comment": "很好用"}, {"product": "B", "sentiment": "negative", "comment": "界面太复杂了"}, {"product": "C", "sentiment": "negative", "comment": "经常崩溃"} ] } 然后提示模型：“请分析以上 JSON 格式的客户反馈数据，总结主要的产品问题和用户情感。” 信息优先级编码： 在提示的特定位置（如开头或结尾，取决于模型特性）放置最核心或最紧急的信息，通过位置偏置确保其在注意力计算中获得更高权重。 激活隐性知识图谱与角色设定： LLM 在预训练阶段习得了海量的世界知识与领域知识。提示词不仅是任务指令，更是激活模型内部相关知识图谱的“钥匙”。通过为模型设定明确的**角色 **，可以引导模型调用更深层次的专业知识、以特定风格或视角进行推理和生成。
...</p></div><footer class=entry-footer></footer><a class=entry-link aria-label="post link to " href=https://bsong2015.github.io/blog/posts/artificial-intelligence/08-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent></h2></header><div class=entry-content><p>分类问题评价标准详解及选择指南 在机器学习领域，分类模型的性能评估至关重要。选择合适的评价标准能够帮助我们更好地理解模型的优劣，并针对性地进行优化。本文将详细介绍几种常用的分类问题评价标准，并探讨如何根据具体场景选择最合适的标准。
在介绍具体指标前，我们首先需要理解混淆矩阵 (Confusion Matrix)，它是衡量分类模型性能的基础。对于一个二元分类问题（例如，判断邮件是否为垃圾邮件），混淆矩阵包含以下四个值：
真正例 (True Positives, TP)： 实际为正例，模型也预测为正例的样本数。 假正例 (False Positives, FP)： 实际为负例，但模型错误地预测为正例的样本数。 真负例 (True Negatives, TN)： 实际为负例，模型也预测为负例的样本数。 假负例 (False Negatives, FN)： 实际为正例，但模型错误地预测为负例的样本数。 常用评价标准 1. 精确率 (Precision)
定义与直觉： 精确率，又称查准率，衡量的是所有被模型预测为正例的样本中，有多少是真正的正例。它回答了这样一个问题：“在模型预测为正例的结果中，有多少是准确的？” 计算方式： TP / (TP + FP) 适用场景： 当我们非常关注预测的准确性，即不希望将负例错误地识别为正例时（例如，在垃圾邮件检测中，我们不希望将重要的非垃圾邮件错误地标记为垃圾邮件，导致用户错过重要信息），精确率是一个重要的指标。高精确率意味着假正例较少。 注意事项： 单独看精确率可能具有误导性。例如，一个模型只将它最有把握的一个样本预测为正例，并且这个样本确实是正例，那么精确率就是100%，但这并不代表模型在所有正例上都表现良好。 2. 召回率 (Recall) / 真正例率 (True Positive Rate, TPR) / 敏感度 (Sensitivity)
定义与直觉： 召回率，又称查全率，衡量的是所有实际为正例的样本中，有多少被模型成功地预测出来了。它回答了这样一个问题：“在所有真实的正例中，模型找回了多少？” 计算方式： TP / (TP + FN) 适用场景： 当我们希望尽可能多地找出所有正例，不希望漏掉任何一个正例时（例如，在疾病诊断中，我们希望尽可能找出所有患病的病人，避免漏诊导致严重后果），召回率是一个重要的指标。高召回率意味着假负例较少。 注意事项： 同样，单独看召回率也可能具有误导性。如果一个模型将所有样本都预测为正例，那么召回率就是100%（因为所有真实的正例都被“找回”了），但这可能导致大量的假正例，从而使精确率非常低。 3. 准确率 (Accuracy)
定义与直觉： 准确率衡量的是所有样本（包括正例和负例）中被正确分类的比例。 计算方式： (TP + TN) / (TP + FP + TN + FN) 适用场景： 当数据类别分布均衡，且所有类别的预测准确性同等重要时，准确率是一个简单直观的评价指标。它易于向非技术人员解释。 注意事项： 在类别不均衡的数据集上，准确率可能会产生误导。例如，如果90%的样本属于负类，模型即使将所有样本都预测为负类，也能达到90%的准确率，但这并不意味着模型具有良好的泛化能力。此外，准确率的计算依赖于分类阈值的选择。 4. F1 分数 (F1 Score)
...</p></div><footer class=entry-footer></footer><a class=entry-link aria-label="post link to " href=https://bsong2015.github.io/blog/posts/artificial-intelligence/09-%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent></h2></header><div class=entry-content><p>揭秘 Chatbot Arena 排行榜：从 ELO 到新算法，AI 大模型座次如何排定？ 相信很多人都对 Chatbot Arena 不陌生。这是一个非常酷的平台，让我们可以匿名地对两个大型语言模型（LLM）的回复进行“盲选”投票，然后根据大家的偏好给模型们排座次。这个排行榜已经成为衡量 LLM 相对实力的重要参考。
但你是否好奇，这个排行榜是如何产生的？模型们的分数是怎么计算的？为什么 Chatbot Arena 还升级了排名算法？今天，我们就来一起揭开它背后的秘密。
一开始，用 ELO 来给模型排座次 你可能在国际象棋或者一些电子竞技中听说过 ELO 等级分系统。简单来说，这是一个计算选手相对实力水平的方法：
初始分数： 每个新“选手”（在 Chatbot Arena 里就是每个 LLM）都有一个初始分数。 比赛决胜负： 当两个模型进行“对战”（即用户选择了其中一个模型的回复更优），“胜利”的模型会从“失败”的模型那里“赢”走一些分数。 分数调整： 赢了比自己分高的对手，分数涨得更多；输了给比自己分低的对手，分数掉得也更狠。反之，如果结果符合预期（高分赢低分），分数变动就小一些。 经过大量“比赛”后，表现好的模型分数自然就高了，形成了我们看到的排行榜。Chatbot Arena 最初就采用了这种经典的在线 ELO 系统。这种方法的好处是可扩展性强，能处理大量模型；而且增量友好，新模型加入后，通过少量对战就能快速获得初始排名。
在线 ELO 的“小烦恼”：为什么需要进化？ 经典的在线 ELO 系统非常适合追踪那些技能水平会动态变化的“玩家”，比如不断学习进步的棋手。它会更看重最近的比赛结果。
然而，在 LLM 排名这个场景下，情况有些不同：
模型是相对静态的： 大部分参与评测的 LLM，其模型权重在评测期间是固定的，性能不会像人类选手那样“忽高忽低”或“持续进步”。 “最近比赛”的偏见： 在线 ELO 系统对近期比赛结果的侧重，可能会导致排名因为比赛顺序的改变而产生较大波动。如果把比赛记录倒过来重新计算 ELO 分数，模型的排名可能会发生显著变化。这对于力求稳定反映模型综合实力的排行榜来说，显然不是最理想的。 数据全局性的缺失： 在线 ELO 是一场接一场地更新分数，而 Chatbot Arena 拥有所有历史对战的完整数据。如果能一次性利用所有数据进行计算，无疑能得到更稳健的评估。 新宠儿登场：Bradley-Terry 模型 为了解决在线 ELO 系统的这些局限性，Chatbot Arena 决定转向一种新的排名算法——Bradley-Terry (BT) 模型。
...</p></div><footer class=entry-footer></footer><a class=entry-link aria-label="post link to " href=https://bsong2015.github.io/blog/posts/artificial-intelligence/10-llm%E6%8E%92%E5%90%8D/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://bsong2015.github.io/blog/posts/artificial-intelligence/page/2/>下一页&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://bsong2015.github.io/blog/>万年水的博客</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>