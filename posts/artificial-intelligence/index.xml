<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>人工智能 on 万年水的博客</title><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/</link><description>Recent content in 人工智能 on 万年水的博客</description><generator>Hugo -- 0.147.9</generator><language>zh</language><lastBuildDate>Mon, 01 Jan 0001 00:00:00 +0000</lastBuildDate><atom:link href="https://bsong2015.github.io/blog/posts/artificial-intelligence/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/01-deepseek%E5%BC%BA%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%87%BA%E7%8E%B0%E5%AF%B9%E4%B8%AD%E5%B0%8F%E5%AD%A6%E7%94%9F%E6%95%99%E8%82%B2%E7%9A%84%E8%A6%81%E6%B1%82/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/01-deepseek%E5%BC%BA%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%87%BA%E7%8E%B0%E5%AF%B9%E4%B8%AD%E5%B0%8F%E5%AD%A6%E7%94%9F%E6%95%99%E8%82%B2%E7%9A%84%E8%A6%81%E6%B1%82/</guid><description>&lt;p>DeepSeek 这种强推理模型能够解决奥数题，代表了人工智能在逻辑推理和问题解决能力上的巨大进步。这对中小学教育以及学生素质培养都提出了新的挑战和机遇。中小学生在 AI 时代，应该着重培养以下几个方面的素质，才能更好地适应和驾驭这个快速发展的时代：&lt;/p>
&lt;p>&lt;strong>一、 培养核心认知能力，而非仅仅是知识记忆&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>批判性思维 (Critical Thinking)：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>不再迷信权威答案：&lt;/strong> AI 可以给出答案，但学生需要学会质疑、评估和验证 AI 给出的信息和解决方案，而不是盲目接受。要培养独立思考的能力，对信息进行筛选和辨别。&lt;/li>
&lt;li>&lt;strong>分析和评估信息来源：&lt;/strong> 训练学生分析信息来源的可靠性、偏见性和局限性。例如，了解 AI 模型是基于数据训练的，其结果也可能受到数据质量和算法偏见的影响。&lt;/li>
&lt;li>&lt;strong>逻辑推理和论证：&lt;/strong> 即使 AI 可以做奥数题，学生也要理解解题背后的逻辑和推理过程，锻炼自己的逻辑思维能力，能够构建清晰的论证，并识别逻辑谬误。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>创造性思维 (Creative Thinking)：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>发散性思维和创新：&lt;/strong> AI 擅长在已知框架内进行优化和推理，但人类的创造力在于突破框架、提出新颖的想法和解决方案。要鼓励学生进行发散性思维，培养创新意识，敢于提出独特见解。&lt;/li>
&lt;li>&lt;strong>想象力和艺术感：&lt;/strong> 艺术、音乐、文学等领域仍然是人类创造力的重要体现。发展学生的想象力、审美能力和艺术鉴赏力，这些是 AI 难以完全替代的。&lt;/li>
&lt;li>&lt;strong>解决复杂和模糊问题的能力：&lt;/strong> 真实世界的问题往往是复杂、模糊且充满不确定性的，需要人类运用创造性思维来定义问题、寻找新的解决方案。要培养学生应对复杂性和模糊性的能力。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>问题解决能力 (Problem-Solving)：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>定义和分解问题：&lt;/strong> 即使 AI 能解奥数题，现实生活中的问题往往更复杂。学生需要学会如何清晰地定义问题，将复杂问题分解为可管理的部分，并理解问题的本质。&lt;/li>
&lt;li>&lt;strong>多角度思考和跨学科应用：&lt;/strong> 培养学生从不同角度看待问题，运用跨学科知识和方法来寻找解决方案。例如，一个社会问题可能需要结合经济学、社会学、心理学等多学科知识来解决。&lt;/li>
&lt;li>&lt;strong>迭代和实验精神：&lt;/strong> 解决复杂问题通常需要多次尝试和迭代。要培养学生的实验精神，不怕失败，从错误中学习，不断改进解决方案。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>二、 掌握必要的数字技能和 AI 工具应用能力&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>基础数字素养 (Digital Literacy)：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>信息检索和筛选：&lt;/strong> AI 时代信息爆炸，学生需要掌握高效的信息检索技巧，并学会从海量信息中筛选出有价值的内容。&lt;/li>
&lt;li>&lt;strong>数字工具应用：&lt;/strong> 熟练使用各种数字工具，包括办公软件、协作平台、在线学习资源等，提高学习和工作效率。&lt;/li>
&lt;li>&lt;strong>网络安全和信息保护意识：&lt;/strong> 了解网络安全风险，保护个人信息和数据安全，负责任地使用网络资源。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>AI 工具的理解和应用 (AI Tool Proficiency)：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>了解 AI 的基本原理和应用场景：&lt;/strong> 不需要深入了解 AI 的技术细节，但需要理解 AI 的基本工作原理，了解 AI 在各个领域的应用场景和潜力。&lt;/li>
&lt;li>&lt;strong>学会使用 AI 辅助学习工具：&lt;/strong> 例如，利用 AI 驱动的搜索引擎更高效地查找资料，使用 AI 写作工具辅助写作，利用 AI 辅导系统进行个性化学习等。&lt;/li>
&lt;li>&lt;strong>理解 AI 的局限性：&lt;/strong> 认识到 AI 不是万能的，理解 AI 的局限性和潜在的偏见，避免过度依赖 AI。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>编程和计算思维 (Computational Thinking)：&lt;/strong>&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/02-%E6%95%B0%E5%AD%97%E8%BD%BB%E6%96%AD%E9%A3%9F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/02-%E6%95%B0%E5%AD%97%E8%BD%BB%E6%96%AD%E9%A3%9F/</guid><description>&lt;h2 id="数字时代过度依赖与数字极简主义数字轻断食">数字时代过度依赖与数字极简主义：数字轻断食&lt;/h2>
&lt;h3 id="现代社会对数字设备的过度依赖已成为普遍现象并对个人和社会层面产生深远影响">&lt;strong>现代社会对数字设备的过度依赖已成为普遍现象，并对个人和社会层面产生深远影响&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>数字设备的“成瘾性”：&lt;/strong> 随着互联网和智能手机的普及，数字设备不再仅仅是工具，其便捷性和丰富的功能使其具备了类似成瘾的特性，如同早期互联网不发达时难以想象人们会对手机产生如此强烈的依赖。&lt;/li>
&lt;li>&lt;strong>“集体潜意识”般的依赖：&lt;/strong> 无论在地铁、课堂、会议，还是在老年人群体和基层服务人员中，无意识地刷手机已成为一种普遍的习惯，仿佛一种“集体潜意识”。&lt;/li>
&lt;li>&lt;strong>即时获取信息的冲动：&lt;/strong> 遇到问题时，人们习惯性地立即通过手机搜索答案，这种即时满足的习惯进一步加剧了数字依赖。&lt;/li>
&lt;/ul>
&lt;h3 id="借鉴轻断食理念推行数字极简主义">&lt;strong>借鉴“轻断食”理念，推行“数字极简主义”&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>“数字轻断食”的类比：&lt;/strong> 将适度减少数字设备的使用比作身体的轻断食，旨在帮助人们在过度沉溺与完全隔绝之间找到一个健康的平衡点。&lt;/li>
&lt;li>&lt;strong>数字依赖带来的负面影响：&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>身体健康问题：&lt;/strong> 长时间使用手机导致眼睛疲劳、身体疲惫等健康问题。&lt;/li>
&lt;li>&lt;strong>认知能力下降：&lt;/strong> 过多碎片化信息和干扰导致注意力分散、记忆力下降，甚至使人“变笨”。&lt;/li>
&lt;li>&lt;strong>信息污染：&lt;/strong> 网络充斥着广告、营销号、虚假信息、煽动性内容以及大量无意义的信息，难以带来真实的快乐和有效的信息。&lt;/li>
&lt;li>&lt;strong>短暂的快乐与长期的损害：&lt;/strong> 类似吸烟，数字设备带来的快乐可能是短暂的，但长期来看会对身心健康造成损害。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>“数字极简主义”的内涵：&lt;/strong> 提倡有意识地减少不必要的数字设备使用，合理规划使用时间，避免过度沉溺，但也不主张完全断网或卸载常用应用等极端做法，因为这在现代社会可能会带来不便甚至负面影响。&lt;/li>
&lt;li>&lt;strong>避免激进的“数字罢工”：&lt;/strong> 突然完全停止使用某些应用或断网可能会适得其反，类似于节食过度容易暴饮暴食。这种激进的方式可能会伤害到自己和身边的人。&lt;/li>
&lt;/ul>
&lt;h3 id="手机依赖的心理机制">&lt;strong>手机依赖的心理机制&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>无意识的习惯：&lt;/strong> 对手机的依赖已根深蒂固，成为一种潜意识行为，即使没有明确的需求，也会忍不住想刷手机来填补空白。&lt;/li>
&lt;li>&lt;strong>错失恐惧症（FOMO，Fear of missing out）：&lt;/strong> 人们总担心错过重要信息或社交动态，即使接收的大部分信息是无用的。&lt;/li>
&lt;li>&lt;strong>通过刷手机排解负面情绪：&lt;/strong> 不开心时，刷短视频或浏览社交媒体可以带来短暂的快乐，成为一种逃避现实的方式。&lt;/li>
&lt;li>&lt;strong>断网行为的复杂性：&lt;/strong> 彻底断网在全民上网的时代显得稀缺，有时可能被视为一种“逃避主义的行为艺术”，但也反映了人们对过度数字连接的反思。&lt;/li>
&lt;/ul>
&lt;h3 id="保持人与手机之间的边界感">&lt;strong>保持人与手机之间的“边界感”&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>类比人际关系：&lt;/strong> 就像人与人之间需要保持适当的距离，人与手机也应如此，避免过度黏在一起。&lt;/li>
&lt;li>&lt;strong>协商式的边界：&lt;/strong> 减少刷手机的时间，例如将原本一下午的刷手机时间缩短为半下午，留出时间做其他事情。&lt;/li>
&lt;li>&lt;strong>克服“停不下来”的困境：&lt;/strong> 意识到手机上的各种内容容易分散注意力，导致忘记原本的目的。&lt;/li>
&lt;li>&lt;strong>固定时间：&lt;/strong> 养成在只在固定时间（如饭前、睡前）使用手机的习惯，同时控制时长，避免无形中将手机融入生活的方方面面。&lt;/li>
&lt;/ul>
&lt;h3 id="利用社交媒体日记戒断手机依赖">&lt;strong>利用社交媒体日记戒断手机依赖&lt;/strong>&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>“以毒攻毒”的方法：&lt;/strong> 在社交媒体上公开记录戒断日记，利用人们的表现欲和连接欲来推动戒断过程。&lt;/li>
&lt;li>&lt;strong>外部监督与支持：&lt;/strong> 通过熟人圈和陌生兴趣圈获得监督、鼓励和支持。&lt;/li>
&lt;li>&lt;strong>自我反思与记录：&lt;/strong> 记录与手机的关系，反思上网行为，了解自己的使用习惯和感受。&lt;/li>
&lt;li>&lt;strong>获得秩序感与意义：&lt;/strong> 在看似无聊的戒断过程中，通过写作和分享找到秩序感和意义，带来内心的稳定感。&lt;/li>
&lt;li>&lt;strong>持续的刻意练习：&lt;/strong> 改变习惯需要时间和坚持，是一个循序渐进的过程。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>最终目标：&lt;/strong> 找到与数字设备之间的健康相处模式，既不完全排斥，也不过度依赖，从而提高生活质量，实现数字生活与现实生活的平衡。&lt;/p>
&lt;h3>&lt;/h3>
&lt;p>&lt;strong>欢迎关注点赞转发&lt;/strong>&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/03-ai%E5%B9%BB%E8%A7%89%E7%9A%84%E5%85%8B%E6%9C%8D%E4%B8%8E%E5%88%A9%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/03-ai%E5%B9%BB%E8%A7%89%E7%9A%84%E5%85%8B%E6%9C%8D%E4%B8%8E%E5%88%A9%E7%94%A8/</guid><description>&lt;h2 id="ai幻觉的克服与利用">AI幻觉的克服与利用&lt;/h2>
&lt;h3 id="什么是ai幻觉">什么是AI幻觉？&lt;/h3>
&lt;p>AI幻觉指的是&lt;strong>模型生成与事实不符、逻辑断裂或脱离上下文的内容，其本质是统计概率驱动的“合理猜测”&lt;/strong>。简单来说，AI幻觉就是指AI一本正经地胡说八道。AI幻觉分为两种类型：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>事实性幻觉 (Factual Hallucination):&lt;/strong> 模型生成的内容与可验证的现实世界事实不一致。例如，糖尿病患者是否可以通过吃蜂蜜代替糖？模型回答“是的，蜂蜜是天然的，可以帮助糖尿病患者稳定血糖水平”，这是一个事实性幻觉，因为蜂蜜会升高血糖。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>忠实性幻觉 (Faithfulness Hallucination):&lt;/strong> 模型生成的内容与用户的指令或上下文不一致。例如，同样提问糖尿病患者是否可以用蜂蜜代替糖，模型回答“蜂蜜富含维生素和矿物质，对提高免疫力很有帮助，因此是一种健康的食品”，虽然这个回答本身没有事实错误，但偏离了用户关于“代替糖”的意图，属于忠实性幻觉。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>AI幻觉不仅限于文本，也可能出现在图像、音频等其他模态中，例如生成不存在的物体、错误的语音内容等。&lt;/strong>&lt;/p>
&lt;h3 id="不同产品的幻觉率对比">不同产品的幻觉率对比&lt;/h3>
&lt;p>对不同大模型的幻觉率进行了初步测试，包括通用性测试和事实性幻觉测试：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>通用性测试：&lt;/strong> 随机生成100条通用提示语，模拟普通用户使用场景。&lt;/p>
&lt;ul>
&lt;li>DeepSeekV3: 2%&lt;/li>
&lt;li>DeepSeekR1: 3%&lt;/li>
&lt;li>Qianwen2.5-Max: 2%&lt;/li>
&lt;li>豆包: 0%&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>事实性幻觉测试：&lt;/strong> 随机抽取300道事实性幻觉测试题，涵盖多个领域。&lt;/p>
&lt;ul>
&lt;li>DeepSeekV3: 29.67%&lt;/li>
&lt;li>DeepSeekR1: 22.33%&lt;/li>
&lt;li>Qianwen2.5-Max: 27.67%&lt;/li>
&lt;li>豆包: 19%&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>根据初步测试结果，无论哪种模型其&lt;strong>幻觉都率较高&lt;/strong>。 这些测试结果是&lt;strong>特定条件下的初步评估&lt;/strong>，实际使用中的幻觉率可能因应用场景、提示词设计等因素而有所不同。不同的评测方法和数据集也可能导致不同的结果。&lt;/p>
&lt;h3 id="ai幻觉的危害">AI幻觉的危害&lt;/h3>
&lt;p>AI幻觉的潜在风险：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>信息污染风险：&lt;/strong> 低门槛和高普及度的AI模型可能产生大量虚假信息，加剧网络信息污染，甚至影响下一代模型的训练数据。&lt;/li>
&lt;li>&lt;strong>信任危机：&lt;/strong> 用户难以辨别AI生成内容的真实性，可能对医疗、法律等专业领域的建议产生长期怀疑。&lt;/li>
&lt;li>&lt;strong>控制欠缺：&lt;/strong> 部分开源模型可能被恶意行为者利用。&lt;/li>
&lt;li>&lt;strong>安全漏洞：&lt;/strong> 错误信息若被用于自动化系统（如金融分析、工业控制），可能引发连锁反应。&lt;/li>
&lt;li>&lt;strong>误导问题：&lt;/strong> AI幻觉在新闻传播、教育、科研等领域也可能带来误导、知识错误等问题，损害信息的准确性和可靠性。&lt;/li>
&lt;/ul>
&lt;h3 id="个人如何利用幻觉">个人如何利用幻觉&lt;/h3>
&lt;p>AI幻觉的有一定的创造力价值，不应仅仅将其视为缺陷，也可以加以利用：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>科学发现：&lt;/strong> 大卫·贝克团队利用AI的“错误折叠”启发了新型蛋白质结构的设计，并获得了诺贝尔化学奖。他们认为AI幻觉是“从零开始设计蛋白质”的关键。&lt;/li>
&lt;li>&lt;strong>文艺与设计：&lt;/strong> AI幻觉可以突破人类思维定式，成为“超现实引擎”，为艺术创作和设计提供新的灵感。&lt;/li>
&lt;li>&lt;strong>娱乐与游戏：&lt;/strong> AI生成的虚拟环境、角色、故事和对话可以增强游戏体验，提供无限的可能性。&lt;/li>
&lt;li>&lt;strong>技术创新：&lt;/strong> DeepMind团队发现，AI在图像分割任务中产生的“超现实边界”意外提升了自动驾驶系统对极端天气的识别精度。&lt;/li>
&lt;li>&lt;strong>新型科研范式：&lt;/strong> 科学界正在构建“AI幻觉-实验验证-理论重构”的研究流程，利用AI的“疯狂创意”进行创新。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>个人可以尝试将AI的幻觉视为一种独特的创意来源，应用于头脑风暴、艺术创作、设计探索等领域，从中获取意想不到的灵感。&lt;/strong> 利用AI幻觉的关键在于区分其创造性价值和潜在的误导性，在需要准确信息的场景下要谨慎对待。&lt;/p>
&lt;h3 id="个人如何克服幻觉">个人如何克服幻觉&lt;/h3>
&lt;p>普通用户应对AI幻觉的三种主要方式：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>联网搜索：&lt;/strong> 开启模型的联网搜索功能，让模型在生成答案时能够检索最新的信息，降低生成不实信息的可能性。测试结果显示，开启联网搜索后，DeepSeekV3和DeepSeekR1的通用性和事实性幻觉率均有所下降。&lt;/li>
&lt;li>&lt;strong>双AI验证/大模型协作：&lt;/strong> 使用一个AI模型生成答案后，再利用其他大模型进行审查，相互监督，交叉验证，以提高答案的可靠性。&lt;/li>
&lt;li>&lt;strong>提示词工程 (Prompt Engineering)：&lt;/strong> 通过精心设计提示词来约束模型的生成行为，降低幻觉发生的概率。具体方法包括：
&lt;ul>
&lt;li>&lt;strong>知识边界限定：&lt;/strong> 通过时间锚定、知识锚定、领域限定符、置信度声明、上下文提示、生成参数协同控制等方式，限制模型在特定范围或条件下生成内容。&lt;/li>
&lt;li>&lt;strong>对抗性提示：&lt;/strong> 强制模型进行自我审查，暴露推理的脆弱点。例如，要求模型在回答后列出可能导致答案错误的假设，或进行链式验证。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>其他应对AI幻觉的方法：&lt;/strong>&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/04-%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE-mcp%E8%BF%9E%E6%8E%A5-ai-%E6%A8%A1%E5%9E%8B%E4%B8%8E%E4%B8%96%E7%95%8C%E7%9A%84%E6%A0%87%E5%87%86%E5%8C%96%E6%A1%A5%E6%A2%81/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/04-%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE-mcp%E8%BF%9E%E6%8E%A5-ai-%E6%A8%A1%E5%9E%8B%E4%B8%8E%E4%B8%96%E7%95%8C%E7%9A%84%E6%A0%87%E5%87%86%E5%8C%96%E6%A1%A5%E6%A2%81/</guid><description>&lt;h2 id="模型上下文协议-mcp连接-ai-模型与世界的标准化桥梁">模型上下文协议 (MCP)：连接 AI 模型与世界的标准化桥梁&lt;/h2>
&lt;h3 id="引言">&lt;strong>引言&lt;/strong>&lt;/h3>
&lt;p>随着人工智能技术的飞速发展，大型语言模型（LLMs）的能力日益强大，它们在理解和生成自然语言方面取得了显著的进步。然而，要让这些模型真正服务于现实世界的应用，仅仅依靠其预训练的知识是远远不够的。它们需要能够安全、高效地访问外部数据源、利用各种工具，并根据用户的具体需求进行定制化的交互。在这样的背景下，由 Anthropic 公司发起并开源的模型上下文协议 (Model Context Protocol, MCP) 应运而生。MCP 旨在为 AI 模型与外部世界建立一座标准化的桥梁，正如 USB-C 接口统一了各种电子设备的连接方式一样，MCP 有望革新 AI 模型的集成方式，极大地提升 AI 应用的灵活性、可扩展性和实用性。&lt;/p>
&lt;h3 id="mxn-集成挑战与标准化需求">&lt;strong>MxN 集成挑战与标准化需求&lt;/strong>&lt;/h3>
&lt;p>在 MCP 出现之前，将 M 个 AI 模型与 N 个不同的工具或数据源集成，往往需要构建 M x N 个定制化的集成方案。这种“MxN”问题导致了复杂性的爆炸式增长，不仅开发和维护成本高昂，而且难以实现不同 AI 模型和外部资源之间的互操作性。例如，一个企业可能同时使用来自不同供应商的多个 LLM，并且需要让它们能够访问企业内部的数据库、文件系统、以及各种外部 API。如果每种 LLM 都需要针对每种数据源和工具进行单独的适配，其工作量和复杂性可想而知。&lt;/p>
&lt;p>为了解决这一瓶颈，行业迫切需要一种标准化的协议，使得每个 AI 模型和每个外部资源只需要遵循一次标准即可实现互联互通。MCP 的目标正是将这种复杂性降低到 M + N 的水平，极大地简化了 AI 集成的过程。语言服务器协议 (Language Server Protocol, LSP) 在代码编辑器和编程语言的集成领域取得了巨大的成功，它通过标准化开发工具与编程语言之间的通信方式，极大地提升了开发效率和用户体验。MCP 正是希望在 AI 集成领域复制 LSP 的成功，通过提供一个通用的接口，让 AI 模型能够以统一的方式与各种外部资源进行交互。&lt;/p>
&lt;h3 id="mcp-的工作原理架构与核心组件">&lt;strong>MCP 的工作原理：架构与核心组件&lt;/strong>&lt;/h3>
&lt;p>MCP 采用经典的客户端-服务器架构。其中，AI 应用程序（例如一个聊天机器人或一个智能助手）扮演 MCP 客户端（或称为主机）的角色，而提供数据、工具或提示的外部系统则扮演 MCP 服务器的角色。&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/05-ai%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%94%BF%E6%B2%BB%E5%80%BE%E5%90%91%E5%92%8C%E8%81%AA%E6%98%8E%E7%A8%8B%E5%BA%A6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/05-ai%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%94%BF%E6%B2%BB%E5%80%BE%E5%90%91%E5%92%8C%E8%81%AA%E6%98%8E%E7%A8%8B%E5%BA%A6/</guid><description>&lt;h2 id="ai模型的政治倾向和聪明程度">AI模型的政治倾向和聪明程度&lt;/h2>
&lt;h3 id="ai的政治倾向">&lt;strong>AI的“政治倾向”&lt;/strong>&lt;/h3>
&lt;p>第一张图（见下图）就是AI模型的“政治倾向”。这个图有两个维度：一个是经济上的立场，从左到右代表着对政府干预经济的不同态度；另一个是社会立场，从下到上代表着对个人自由和社会秩序的不同侧重。&lt;/p>
&lt;p>这张图片展示了一个“AI 政治倾向”图表。它通过一个标准的政治倾向测试（politicalcompass.org/test）来评估不同人工智能模型的政治倾向。&lt;/p>
&lt;ul>
&lt;li>图片的核心是一个二维坐标系，代表了政治倾向。&lt;/li>
&lt;li>&lt;strong>横轴 (Economic):&lt;/strong> 代表经济立场，从左（Economic Left）到右（Economic Right）。左边通常代表支持更多政府干预、福利制度和经济平等；右边则倾向于自由市场、低税收和较少的政府干预。&lt;/li>
&lt;li>&lt;strong>纵轴 (Social):&lt;/strong> 代表社会立场，从下（Social Libertarianism）到上（Social Authoritarianism）。下方代表更倾向于个人自由、容忍不同的生活方式和较少的政府对个人行为的干预；上方则倾向于社会秩序、传统价值观和更强的政府控制。&lt;/li>
&lt;li>这个坐标系将政治立场划分为四个象限，所有的模型现在都落在第三象限，表示AI倾向于经济上的政府干预（如福利制度），但在社会生活上强调个人自由。&lt;/li>
&lt;/ul>
&lt;h3 id="ai的聪明程度">&lt;strong>AI的“聪明程度”&lt;/strong>&lt;/h3>
&lt;p>第二张图（见下图）展示了不同AI模型在门萨智商测试中的得分情况。门萨测试是一种广为认可的智力测试，能大致反映一个人的逻辑思维和问题解决能力。&lt;/p>
&lt;p>图上横轴是智商分数，100分左右是人类的平均水平。可以看到，各种AI模型的得分也各不相同。其中&lt;strong>Gemini 2.5 Pro Exp&lt;/strong>的模型，它的平均智商分数达到了128分。下面是具体的数据图片：&lt;/p>
&lt;h3 id="想象一下">&lt;strong>想象一下&lt;/strong>&lt;/h3>
&lt;p>AI的发展很快，当智商达到140的时候可能带来巨大的进步和机遇，但也伴随着失业、伦理和安全等风险。当达到160的时候可能代表着一个全新的智能时代，其潜力巨大，但也带来了前所未有的挑战，甚至可能涉及人类的生存问题。到那时候它的伦理道德和政治倾向将影响更大。&lt;/p>
&lt;p>参考https://trackingai.org/home&lt;/p>
&lt;h3>&lt;/h3>
&lt;p>&lt;strong>欢迎关注+点赞+转发&lt;/strong>&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/06-qwen3-sota/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/06-qwen3-sota/</guid><description>&lt;p>&lt;strong>标题：阿里的Qwen3确实很强，但“超越”、“登顶”？我们用事实来看！&lt;/strong>&lt;/p>
&lt;p>随着 Qwen3模型的发布，不少文章标题都用了“超越”、“登顶”、“SOTA”等颇具吸引力的词汇，字里行间透露着这款新模型已经力压群雄、独孤求败的意味。&lt;/p>
&lt;p>Qwen3 毫无疑问是一款非常强大的模型，这一点毋庸置疑。但事实是否真的如此绝对？“超越”、“登顶”这些词，我们需要基于更全面的数据来审视。&lt;/p>
&lt;p>我们先看看官方的描述“我们的旗舰模型 Qwen3-235B-A22B 在代码、数学、通用能力等基准测试中，与 DeepSeek-R1、o1、o3-mini、Grok-3 和 Gemini-2.5-Pro 等顶级模型相比，表现出极具竞争力的结果”，极具竞争力还是比较客观的，比其它媒体都准确一些。&lt;/p>
&lt;p>这里有一份包含 Qwen3-235B-A22B 在内，对比多个主流大型模型在一些列评测基准上表现的表格（表格来源: 千问官方公众号）。让我们基于这份&lt;strong>事实数据&lt;/strong>，来理性分析一下 Qwen3-235B-A22B 的能力定位。&lt;/p>
&lt;p>（此处可以插入表格图片，或简单描述表格内容，例如：）&lt;/p>
&lt;p>&lt;strong>数据怎么说？&lt;/strong>&lt;/p>
&lt;p>毋庸置疑，Qwen3-235B-A22B 的成绩非常亮眼：&lt;/p>
&lt;ul>
&lt;li>在 &lt;strong>ArenaHard&lt;/strong>（复杂对话/指令）上获得 95.6 分。&lt;/li>
&lt;li>在 &lt;strong>AIME 数学竞赛&lt;/strong>基准（&amp;lsquo;24 和 &amp;lsquo;25）上分别获得 85.7 和 81.5 的高分。&lt;/li>
&lt;li>在 &lt;strong>Codeforces Elo Rating&lt;/strong> 这一衡量竞技编程能力的指标上达到 2056 分。&lt;/li>
&lt;li>在 &lt;strong>LiveBench&lt;/strong> 和 &lt;strong>MultiIF&lt;/strong> 等基准上也表现出色。&lt;/li>
&lt;/ul>
&lt;p>这些分数表明，Qwen3-235B-A22B 在通用能力、数学推理和编程等核心领域确实具备顶级模型的实力。特别是在 ArenaHard 和 AIME 等评测中，它的分数是名列前茅的。&lt;/p>
&lt;p>&lt;strong>但是，“超越”和“登顶”了吗？&lt;/strong>&lt;/p>
&lt;p>当我们审视表格中的其他模型，尤其是 &lt;strong>Gemini 2.5-Pro&lt;/strong> 时，会发现情况并非那么简单：&lt;/p>
&lt;ul>
&lt;li>在 &lt;strong>ArenaHard&lt;/strong> 上，Gemini 2.5-Pro 获得了 96.4 分，略高于 Qwen3-235B-A22B。&lt;/li>
&lt;li>在 &lt;strong>AIME'24&lt;/strong> (92.0 分) 和 &lt;strong>AIME'25&lt;/strong> (86.7 分) 上，Gemini 2.5-Pro 的分数均高于 Qwen3-235B-A22B。&lt;/li>
&lt;li>在 &lt;strong>LiveBench&lt;/strong> (82.4 分) 和 &lt;strong>MultiIF&lt;/strong> (77.8 分) 上，Gemini 2.5-Pro 的得分也更高。&lt;/li>
&lt;li>即使在 Qwen3-235B-A22B 表现优秀的 &lt;strong>Codeforces Elo Rating&lt;/strong> (2056 分) 上，Gemini 2.5-Pro 也取得了 2001 分的非常接近的成绩。&lt;/li>
&lt;/ul>
&lt;p>从这份数据来看，Gemini 2.5-Pro 在多个关键基准上表现与 Qwen3-235B-A22B 相当，甚至在部分通用能力和数学评测中分数更高。表格中的 Deepseek-Rl、OpenAI-0x01 等模型在某些单项上也展现出了各自的优势。&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/07-ai%E5%8A%A9%E6%89%8B%E5%BC%80%E5%8F%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/07-ai%E5%8A%A9%E6%89%8B%E5%BC%80%E5%8F%91/</guid><description>&lt;h2 id="让ai听懂人话没那么简单揭秘自然语言交互背后的挑战与解决方案">让AI听懂“人话”，没那么简单！揭秘自然语言交互背后的挑战与解决方案&lt;/h2>
&lt;p>想象一下，你不再需要点击层层菜单，填写繁琐表单，只需要像和同事聊天一样，对电脑或手机说：“帮我查一下上个月销售额最高的三个城市”或者“把这个月未支付的订单都导出来”。这就是产品交互“AI化”的核心目标：&lt;strong>用最自然、最直观的语言来控制复杂的系统&lt;/strong>。&lt;/p>
&lt;p>这种革命性的交互方式，深度依赖于大语言模型（LLM）强大的自然语言理解能力，将用户的“人话”精准转换成系统能执行的指令，也就是所谓的“Function Call”（函数调用）。虽然前景光明，但将这一愿景落地到实际产品中，却面临着一系列现实挑战。今天，我们就来深入揭秘其中的几个关键问题，并看看业界是如何尝试解决这些挑战的。&lt;/p>
&lt;h3 id="挑战一ai能听懂指令但听准没那么容易function-call-的准确率不高">挑战一：AI能听懂指令，但“听准”没那么容易——Function Call 的准确率不高&lt;/h3>
&lt;p>&lt;strong>问题描述：&lt;/strong>
用户说“帮我新建一个客户”，系统背后可能需要调用一个名为 create_customer 的接口，并需要提供客户姓名、联系方式等参数。Function Call 的核心任务就是识别用户意图是“新建客户”，并从用户的话语中精确提取出所需的参数。然而，实际应用中，AI 识别并执行正确函数和参数的准确率并不总是尽如人意。即使是当前最先进的模型，在伯克利的函数调用测评集PFCL上的综合准确率也只有70%多。这意味着，大约有 30% 的情况下，AI 可能会理解错误，导致执行了不相关的操作，或者因为无法提取必需参数而无法执行用户指令。&lt;/p>
&lt;p>&lt;strong>为什么会这样？&lt;/strong>
自然语言是高度灵活、充满歧义且语境依赖的。用户可能用五花八门的方式表达同一个意思，习惯性地省略信息，使用同义词，甚至表达一些模棱两可的指令。而系统拥有的函数接口则是固定、规范且要求严格的。将灵活多变的“人话”精确无误地映射到规范严谨的“机器指令”，本身就是一项极具挑战性的任务。&lt;/p>
&lt;p>&lt;strong>解决方案：&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>优化函数描述：&lt;/strong> 这是基础中的基础。为 LLM 提供&lt;strong>清晰、准确、带有高质量示例&lt;/strong>的函数描述至关重要。函数名应直观易懂，描述要详细说明其功能、每个参数的含义、数据类型和格式要求。这就像为 AI 提供一份详尽的操作手册。&lt;/li>
&lt;li>&lt;strong>Few-shot Learning以及提示词工程：&lt;/strong> 在给 LLM 的 Prompt 中，加入少量&lt;strong>高质量的&lt;/strong>用户 query 到 Function Call 的映射示例。通过这些具体的例子，AI 能更好地理解如何从相似的表达中提取关键信息并映射到正确的函数。&lt;/li>
&lt;li>&lt;strong>引入中间层（意图识别与参数提取）：&lt;/strong> 不完全依赖 LLM 一步到位完成所有工作。可以在 LLM 之外增加一个&lt;strong>专门的意图识别模块&lt;/strong>，先行判断用户的核心意图（例如，是“查询订单”还是“创建用户”），再根据意图将请求导向相关的函数子集。之后，可以使用 LLM 或更专业的 NLP 模型进行参数的提取和校验。这种模块化的流水线方式可以显著提高特定环节的处理准确率。&lt;/li>
&lt;li>&lt;strong>后置校验与确认：&lt;/strong> 在 AI 生成 Function Call 指令后，&lt;strong>不立即执行&lt;/strong>，而是进行多重校验。例如，检查提取的参数是否符合函数要求的格式、范围等。更进一步，可以将解析出的用户意图和关键参数用自然语言反馈给用户进行&lt;strong>二次确认&lt;/strong>：“您是希望创建一个名为 [客户姓名] 的新客户吗？”等待用户明确肯定后再执行。&lt;/li>
&lt;/ol>
&lt;h3 id="挑战二一句一句交流没问题但聊复杂事情就犯晕多轮-function-call-准确率更低">挑战二：一句一句交流没问题，但聊复杂事情就犯晕——多轮 Function Call 准确率更低&lt;/h3>
&lt;p>&lt;strong>问题描述：&lt;/strong>
如果用户说：“帮我查一下北京的订单”，系统执行查询后，用户接着说“只要金额大于 1000 的”，然后又说“把这些订单按时间排序”。这是一个典型的多轮对话场景。系统需要在后续轮次中&lt;strong>记住并利用之前的上下文&lt;/strong>（正在查询订单、限定了北京的条件），并理解用户的后续指令（增加金额条件、改变排序方式）是基于前序操作的&lt;strong>细化、修改或进一步处理&lt;/strong>，而不是全新的请求。然而，在复杂的多轮对话场景下，Function Call 的准确率会大幅下降，有时甚至低于 30%，导致交互体验断裂。&lt;/p>
&lt;p>&lt;strong>为什么会这样？&lt;/strong>
多轮对话不仅考验单轮的语言理解能力，更对系统的&lt;strong>对话状态管理&lt;/strong>和&lt;strong>跨轮次的关联理解&lt;/strong>提出了更高要求。AI 需要克服以下困难：&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/08-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/08-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B/</guid><description>&lt;h2 id="提示词工程进阶从指令艺术到与大模型共舞的科学">提示词工程进阶：从指令艺术到与大模型共舞的科学&lt;/h2>
&lt;p>在大型语言模型（LLM）日益成为技术革新基石的今天，提示词工程（Prompt Engineering）已不再是简单的“告诉模型做什么”，而是演进为一门集认知科学、计算机科学与语言学于一体的复杂学科。对于专业的提示词工程师而言，追求的不仅是“可用”的输出，更是极致的性能、卓越的鲁棒性、精细的可控性以及对模型潜能的深度挖掘。本文基于 Kaggle Whitepaper on Prompt Engineering 和 PromptingGuide.ai 的前沿洞见，旨在为有经验的从业者提供新的视角与启发，深入探讨提示词工程的高级策略与实践，并辅以具体示例。&lt;/p>
&lt;p>&lt;strong>一、 洞悉模型心智：超越表层指令的深层交互&lt;/strong>&lt;/p>
&lt;p>提示词工程不仅需要注重指令的清晰与具体，更需理解这些指令如何在模型的内部机制中发挥作用，实现与模型的深度“共舞”。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>引导注意力焦点与明确性：&lt;/strong> Transformer 架构的核心在于注意力机制。精心设计的提示词能有效引导模型将计算资源聚焦于输入中最关键、最相关的部分。指令的&lt;strong>清晰度 (Clarity)&lt;/strong> 和&lt;strong>具体性 (Specificity)&lt;/strong> 至关重要，避免歧义，明确任务目标。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>不够明确的提示：&lt;/strong>&lt;/p>
&lt;pre>&lt;code> “帮我计划一个周末去处。”
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>优化后的引导注意力焦点的提示：&lt;/strong>&lt;/p>
&lt;pre>&lt;code> “我们一家三口（两个大人，一个5岁小孩）周末想在北京市内找个地方玩一天。我们主要想去一个适合孩子、能亲近自然的地方，最好交通方便，单程不要超过1.5小时车程。请推荐2-3个选择，并简要说明每个地方的特色、适合孩子的点以及大致的门票和交通方式”
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>上下文学习（In-Context Learning / Few-Shot Prompting）：&lt;/strong> 这是 LLM 的一个强大能力，通过在提示中提供少量任务示例（demonstrations），模型可以快速学习并模仿示例的模式来完成新任务，而无需更新模型参数。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>示例（情感分类 Few-Shot）：&lt;/strong>
&lt;pre tabindex="0">&lt;code>文本：这家餐厅的食物太美味了！
情感：积极
文本：等了快一个小时，服务太差了。
情感：消极
文本：电影情节一般，但演员表现不错。
情感：中性
文本：我对这个产品非常失望，完全不值这个价。
情感：
&lt;/code>&lt;/pre>模型会根据提供的示例推断出最后一个文本的情感为“消极”。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>精细化上下文管理：&lt;/strong> 模型的上下文窗口是有限的“记忆空间”。处理长文本或复杂对话时，如何高效利用这一资源至关重要。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>滑动窗口与摘要注入：&lt;/strong> 对于超出单次处理上限的长文本，可采用滑动窗口技术。处理后续窗口时，将前序窗口的关键信息以简洁摘要形式注入当前提示，确保上下文的连贯性与核心信息的传递。
&lt;ul>
&lt;li>&lt;strong>示例：&lt;/strong> 处理一本200页的书籍。分块处理时，处理第21-40页的提示可包含：“这是书籍的第21-40页。&lt;strong>前20页的核心摘要是：[此处插入第一区块的摘要]&lt;/strong>。请基于此继续分析当前区块，识别关键主题和论点。”&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>结构化信息封装：&lt;/strong> 将非结构化信息转化为模型更易解析和利用的结构化（如 JSON, XML）或半结构化格式输入，可显著提升信息利用效率，减少上下文浪费。
&lt;ul>
&lt;li>&lt;strong>示例：&lt;/strong> 客户反馈：“产品A很好用，但B的界面太复杂了，而且C经常崩溃。” 可转化为：
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;customer_feedback&amp;#34;&lt;/span>: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#f92672">&amp;#34;product&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;A&amp;#34;&lt;/span>, &lt;span style="color:#f92672">&amp;#34;sentiment&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;positive&amp;#34;&lt;/span>, &lt;span style="color:#f92672">&amp;#34;comment&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;很好用&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#f92672">&amp;#34;product&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;B&amp;#34;&lt;/span>, &lt;span style="color:#f92672">&amp;#34;sentiment&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;negative&amp;#34;&lt;/span>, &lt;span style="color:#f92672">&amp;#34;comment&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;界面太复杂了&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {&lt;span style="color:#f92672">&amp;#34;product&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;C&amp;#34;&lt;/span>, &lt;span style="color:#f92672">&amp;#34;sentiment&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;negative&amp;#34;&lt;/span>, &lt;span style="color:#f92672">&amp;#34;comment&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;经常崩溃&amp;#34;&lt;/span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>然后提示模型：“请分析以上 JSON 格式的客户反馈数据，总结主要的产品问题和用户情感。”&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>信息优先级编码：&lt;/strong> 在提示的特定位置（如开头或结尾，取决于模型特性）放置最核心或最紧急的信息，通过位置偏置确保其在注意力计算中获得更高权重。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>激活隐性知识图谱与角色设定：&lt;/strong> LLM 在预训练阶段习得了海量的世界知识与领域知识。提示词不仅是任务指令，更是激活模型内部相关知识图谱的“钥匙”。通过为模型设定明确的**角色 **，可以引导模型调用更深层次的专业知识、以特定风格或视角进行推理和生成。&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/09-%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/09-%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/</guid><description>&lt;h2 id="分类问题评价标准详解及选择指南">分类问题评价标准详解及选择指南&lt;/h2>
&lt;p>在机器学习领域，分类模型的性能评估至关重要。选择合适的评价标准能够帮助我们更好地理解模型的优劣，并针对性地进行优化。本文将详细介绍几种常用的分类问题评价标准，并探讨如何根据具体场景选择最合适的标准。&lt;/p>
&lt;p>在介绍具体指标前，我们首先需要理解&lt;strong>混淆矩阵 (Confusion Matrix)&lt;/strong>，它是衡量分类模型性能的基础。对于一个二元分类问题（例如，判断邮件是否为垃圾邮件），混淆矩阵包含以下四个值：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>真正例 (True Positives, TP)：&lt;/strong> 实际为正例，模型也预测为正例的样本数。&lt;/li>
&lt;li>&lt;strong>假正例 (False Positives, FP)：&lt;/strong> 实际为负例，但模型错误地预测为正例的样本数。&lt;/li>
&lt;li>&lt;strong>真负例 (True Negatives, TN)：&lt;/strong> 实际为负例，模型也预测为负例的样本数。&lt;/li>
&lt;li>&lt;strong>假负例 (False Negatives, FN)：&lt;/strong> 实际为正例，但模型错误地预测为负例的样本数。&lt;/li>
&lt;/ul>
&lt;h3 id="常用评价标准">常用评价标准&lt;/h3>
&lt;p>&lt;strong>1. 精确率 (Precision)&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>定义与直觉：&lt;/strong> 精确率，又称查准率，衡量的是所有被模型预测为正例的样本中，有多少是真正的正例。它回答了这样一个问题：“在模型预测为正例的结果中，有多少是准确的？”&lt;/li>
&lt;li>&lt;strong>计算方式：&lt;/strong> TP / (TP + FP)&lt;/li>
&lt;li>&lt;strong>适用场景：&lt;/strong> 当我们非常关注预测的准确性，即不希望将负例错误地识别为正例时（例如，在垃圾邮件检测中，我们不希望将重要的非垃圾邮件错误地标记为垃圾邮件，导致用户错过重要信息），精确率是一个重要的指标。高精确率意味着假正例较少。&lt;/li>
&lt;li>&lt;strong>注意事项：&lt;/strong> 单独看精确率可能具有误导性。例如，一个模型只将它最有把握的一个样本预测为正例，并且这个样本确实是正例，那么精确率就是100%，但这并不代表模型在所有正例上都表现良好。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>2. 召回率 (Recall) / 真正例率 (True Positive Rate, TPR) / 敏感度 (Sensitivity)&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>定义与直觉：&lt;/strong> 召回率，又称查全率，衡量的是所有实际为正例的样本中，有多少被模型成功地预测出来了。它回答了这样一个问题：“在所有真实的正例中，模型找回了多少？”&lt;/li>
&lt;li>&lt;strong>计算方式：&lt;/strong> TP / (TP + FN)&lt;/li>
&lt;li>&lt;strong>适用场景：&lt;/strong> 当我们希望尽可能多地找出所有正例，不希望漏掉任何一个正例时（例如，在疾病诊断中，我们希望尽可能找出所有患病的病人，避免漏诊导致严重后果），召回率是一个重要的指标。高召回率意味着假负例较少。&lt;/li>
&lt;li>&lt;strong>注意事项：&lt;/strong> 同样，单独看召回率也可能具有误导性。如果一个模型将所有样本都预测为正例，那么召回率就是100%（因为所有真实的正例都被“找回”了），但这可能导致大量的假正例，从而使精确率非常低。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>3. 准确率 (Accuracy)&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>定义与直觉：&lt;/strong> 准确率衡量的是所有样本（包括正例和负例）中被正确分类的比例。&lt;/li>
&lt;li>&lt;strong>计算方式：&lt;/strong> (TP + TN) / (TP + FP + TN + FN)&lt;/li>
&lt;li>&lt;strong>适用场景：&lt;/strong> 当数据类别分布均衡，且所有类别的预测准确性同等重要时，准确率是一个简单直观的评价指标。它易于向非技术人员解释。&lt;/li>
&lt;li>&lt;strong>注意事项：&lt;/strong> 在类别不均衡的数据集上，准确率可能会产生误导。例如，如果90%的样本属于负类，模型即使将所有样本都预测为负类，也能达到90%的准确率，但这并不意味着模型具有良好的泛化能力。此外，准确率的计算依赖于分类阈值的选择。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>4. F1 分数 (F1 Score)&lt;/strong>&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/10-llm%E6%8E%92%E5%90%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/10-llm%E6%8E%92%E5%90%8D/</guid><description>&lt;h2 id="揭秘-chatbot-arena-排行榜从-elo-到新算法ai-大模型座次如何排定">揭秘 Chatbot Arena 排行榜：从 ELO 到新算法，AI 大模型座次如何排定？&lt;/h2>
&lt;p>相信很多人都对 &lt;strong>Chatbot Arena&lt;/strong> 不陌生。这是一个非常酷的平台，让我们可以匿名地对两个大型语言模型（LLM）的回复进行“盲选”投票，然后根据大家的偏好给模型们排座次。这个排行榜已经成为衡量 LLM 相对实力的重要参考。&lt;/p>
&lt;p>但你是否好奇，这个排行榜是如何产生的？模型们的分数是怎么计算的？为什么 Chatbot Arena 还升级了排名算法？今天，我们就来一起揭开它背后的秘密。&lt;/p>
&lt;h3 id="一开始用-elo-来给模型排座次">一开始，用 ELO 来给模型排座次&lt;/h3>
&lt;p>你可能在国际象棋或者一些电子竞技中听说过 &lt;strong>ELO 等级分系统&lt;/strong>。简单来说，这是一个计算选手相对实力水平的方法：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>初始分数：&lt;/strong> 每个新“选手”（在 Chatbot Arena 里就是每个 LLM）都有一个初始分数。&lt;/li>
&lt;li>&lt;strong>比赛决胜负：&lt;/strong> 当两个模型进行“对战”（即用户选择了其中一个模型的回复更优），“胜利”的模型会从“失败”的模型那里“赢”走一些分数。&lt;/li>
&lt;li>&lt;strong>分数调整：&lt;/strong> 赢了比自己分高的对手，分数涨得更多；输了给比自己分低的对手，分数掉得也更狠。反之，如果结果符合预期（高分赢低分），分数变动就小一些。&lt;/li>
&lt;/ul>
&lt;p>经过大量“比赛”后，表现好的模型分数自然就高了，形成了我们看到的排行榜。Chatbot Arena 最初就采用了这种经典的在线 ELO 系统。这种方法的好处是&lt;strong>可扩展性强&lt;/strong>，能处理大量模型；而且&lt;strong>增量友好&lt;/strong>，新模型加入后，通过少量对战就能快速获得初始排名。&lt;/p>
&lt;h3 id="在线-elo-的小烦恼为什么需要进化">在线 ELO 的“小烦恼”：为什么需要进化？&lt;/h3>
&lt;p>经典的在线 ELO 系统非常适合追踪那些技能水平会动态变化的“玩家”，比如不断学习进步的棋手。它会更看重&lt;strong>最近的比赛结果&lt;/strong>。&lt;/p>
&lt;p>然而，在 LLM 排名这个场景下，情况有些不同：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>模型是相对静态的：&lt;/strong> 大部分参与评测的 LLM，其模型权重在评测期间是固定的，性能不会像人类选手那样“忽高忽低”或“持续进步”。&lt;/li>
&lt;li>&lt;strong>“最近比赛”的偏见：&lt;/strong> 在线 ELO 系统对近期比赛结果的侧重，可能会导致排名因为比赛顺序的改变而产生较大波动。如果把比赛记录倒过来重新计算 ELO 分数，模型的排名可能会发生显著变化。这对于力求稳定反映模型综合实力的排行榜来说，显然不是最理想的。&lt;/li>
&lt;li>&lt;strong>数据全局性的缺失：&lt;/strong> 在线 ELO 是一场接一场地更新分数，而 Chatbot Arena 拥有所有历史对战的完整数据。如果能一次性利用所有数据进行计算，无疑能得到更稳健的评估。&lt;/li>
&lt;/ol>
&lt;h3 id="新宠儿登场bradley-terry-模型">新宠儿登场：Bradley-Terry 模型&lt;/h3>
&lt;p>为了解决在线 ELO 系统的这些局限性，Chatbot Arena 决定转向一种新的排名算法——&lt;strong>Bradley-Terry (BT) 模型&lt;/strong>。&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/11-%E7%B2%BE%E9%80%9A%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%BB%8E%E5%9F%BA%E7%A1%80%E5%88%B0%E9%AB%98%E7%BA%A7%E7%AD%96%E7%95%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/11-%E7%B2%BE%E9%80%9A%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E4%BB%8E%E5%9F%BA%E7%A1%80%E5%88%B0%E9%AB%98%E7%BA%A7%E7%AD%96%E7%95%A5/</guid><description>&lt;p>作为机器学习领域的关键组成部分，&lt;strong>特征工程&lt;/strong>是将原始数据转化为模型可理解和利用格式的艺术与科学。它不仅能显著提升模型性能，还能增强模型的可靠性和鲁棒性。本文将深入探讨特征工程的各项策略，从基础概念到高级应用，助您充分挖掘数据的潜力。&lt;/p>
&lt;h2 id="一-机器学习的基石特征工程">一. 机器学习的基石：特征工程&lt;/h2>
&lt;h3 id="什么是特征工程">&lt;strong>什么是特征工程？&lt;/strong>&lt;/h3>
&lt;p>从核心上讲，&lt;strong>特征工程&lt;/strong>是利用领域知识，从原始数据中创建、选择和转换输入变量（即“特征”）的过程。其核心目标是提升机器学习模型的性能、可解释性与鲁棒性。它通过精准筛选并以算法易于理解和高效利用的方式呈现信息来实现这一点。&lt;/p>
&lt;h3 id="为何特征工程如此关键">&lt;strong>为何特征工程如此关键？&lt;/strong>&lt;/h3>
&lt;p>“垃圾进，垃圾出”（Garbage In, Garbage Out）这句格言在机器学习领域尤为贴切。输入特征的质量直接决定模型表现。当特征不相关、充满噪声或结构不良时，即使最先进的算法也无法有效运行。因此，高效的特征工程对以下方面至关重要：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>模型性能&lt;/strong>：精心设计的特征能够显著提高预测准确性、减少错误，并使模型具有更强的泛化能力。它们帮助算法识别那些否则可能被掩盖的深层模式。&lt;/li>
&lt;li>&lt;strong>模型可解释性&lt;/strong>：结构良好的特征使模型更易于理解和解释。例如，“债务收入比”这一特征比单独的原始债务和收入数据更具直观解释性。&lt;/li>
&lt;li>&lt;strong>鲁棒性&lt;/strong>：旨在处理异常值、缺失值或不同尺度数据的特征，能使模型更好地应对真实世界数据中的不完善性，提高其弹性。&lt;/li>
&lt;li>&lt;strong>降低复杂性与训练时间&lt;/strong>：通过提供信息更丰富的特征，我们或许能够采用更简单、训练更快且不易过拟合的模型。&lt;/li>
&lt;li>&lt;strong>解决算法局限性&lt;/strong>：某些算法对特征尺度敏感（如支持向量机SVM、K近邻k-NN），或无法直接处理类别数据（如大多数线性模型）。特征工程能有效解决这些内在限制。&lt;/li>
&lt;/ol>
&lt;h3 id="艺术与科学的融合">&lt;strong>“艺术”与“科学”的融合&lt;/strong>&lt;/h3>
&lt;p>特征工程常被视为艺术与科学的结合：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>科学性&lt;/strong>：它包含系统化过程，如统计分析、数据转换和算法化特征选择。缩放、编码和降维等技术都遵循明确的数学原理。&lt;/li>
&lt;li>&lt;strong>艺术性&lt;/strong>：它高度依赖于&lt;strong>领域专业知识&lt;/strong>、直觉和创造力。对业务问题、数据生成过程及领域细节的深刻理解，常能催生出纯粹算法难以发现的、具有高度预测性的新颖特征。&lt;/li>
&lt;/ul>
&lt;p>最有效的特征工程实践，往往是将系统性探索与富有洞察力、由领域驱动的假设生成相结合，位于艺术与科学的交汇点。&lt;/p>
&lt;h2 id="二-特征工程的工作流程与思维模式">二. 特征工程的工作流程与思维模式&lt;/h2>
&lt;p>特征工程并非一次性任务，而是一个深度融入机器学习生命周期的迭代过程。&lt;/p>
&lt;h3 id="理解数据探索性数据分析eda是前提">&lt;strong>理解数据：探索性数据分析（EDA）是前提&lt;/strong>&lt;/h3>
&lt;p>在创建新特征之前，必须彻底理解现有特征。&lt;strong>探索性数据分析（EDA）&lt;/strong> 对于以下方面至关重要：&lt;/p>
&lt;ul>
&lt;li>识别数据类型（数值型、类别型、文本型、日期/时间型）。&lt;/li>
&lt;li>理解数据分布、集中趋势和离散程度。&lt;/li>
&lt;li>检测缺失值、异常值和潜在的数据质量问题。&lt;/li>
&lt;li>可视化变量之间以及与目标变量之间的关系。&lt;/li>
&lt;li>形成关于潜在有用特征的初步假设。&lt;/li>
&lt;/ul>
&lt;h3 id="领域知识的角色">&lt;strong>领域知识的角色&lt;/strong>&lt;/h3>
&lt;p>领域专业知识是无价之宝。熟悉问题领域的人能够：&lt;/p>
&lt;ul>
&lt;li>建议相关的外部数据源。&lt;/li>
&lt;li>识别变量之间有意义的交互作用。&lt;/li>
&lt;li>提出反映潜在过程的转换（例如，在销售数据集中计算“客户生命周期价值”）。&lt;/li>
&lt;li>验证工程化特征的合理性。&lt;/li>
&lt;/ul>
&lt;h3 id="特征工程的迭代性质">&lt;strong>特征工程的迭代性质&lt;/strong>&lt;/h3>
&lt;p>特征工程很少是线性过程，通常包括以下循环：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>构思与创建&lt;/strong>：产生新的特征想法。&lt;/li>
&lt;li>&lt;strong>实施&lt;/strong>：编写特征转换的代码。&lt;/li>
&lt;li>&lt;strong>评估&lt;/strong>：评估新特征对模型性能的影响（通常使用验证集）。&lt;/li>
&lt;li>&lt;strong>优化&lt;/strong>：根据评估结果修改或舍弃特征。&lt;/li>
&lt;/ul>
&lt;p>随着您获得更多洞察并努力提升模型性能，这个循环会不断重复。&lt;/p>
&lt;h3 id="评估特征质量">&lt;strong>评估特征质量&lt;/strong>&lt;/h3>
&lt;p>如何判断一个新特征是否优秀？&lt;/p>
&lt;ul>
&lt;li>&lt;strong>模型性能提升&lt;/strong>：该特征是否在留出的验证集上改善了所选的评估指标（如准确率、F1分数、AUC）？&lt;/li>
&lt;li>&lt;strong>特征重要性得分&lt;/strong>：许多模型（如基于树的模型、带正则化的线性模型）会提供特征重要性得分。&lt;/li>
&lt;li>&lt;strong>与目标变量的相关性&lt;/strong>：对于监督学习，与目标变量高度相关（同时避免多重共线性）的特征通常很有用。&lt;/li>
&lt;li>&lt;strong>稳定性&lt;/strong>：该特征的预测能力在不同的数据子集或时间段内是否保持一致？&lt;/li>
&lt;li>&lt;strong>可解释性&lt;/strong>：该特征在问题背景下是否有意义？&lt;/li>
&lt;/ul>
&lt;h2 id="三-核心特征工程技术">三. 核心特征工程技术&lt;/h2>
&lt;p>本节将探讨一些常用技术，并进行分类以便清晰理解。&lt;/p>
&lt;h3 id="特征创建">&lt;strong>特征创建&lt;/strong>&lt;/h3>
&lt;p>特征创建是特征工程的基础，旨在通过结合或分解现有数据，生成更具信息量的变量。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>1. 分解 (Decomposition)&lt;/strong>：将复杂特征分解为更简单、信息更丰富的部分。
&lt;ul>
&lt;li>&lt;strong>示例 (日期/时间)&lt;/strong>：从一个 timestamp 如 2023-10-27 14:30:00，可以提取：
&lt;ul>
&lt;li>年份 (Year): 2023&lt;/li>
&lt;li>月份 (Month): 10&lt;/li>
&lt;li>月中日期 (DayOfMonth): 27&lt;/li>
&lt;li>周中日期 (DayOfWeek): 4 (星期五)&lt;/li>
&lt;li>小时 (Hour): 14&lt;/li>
&lt;li>是否周末 (IsWeekend): True/False&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>原因&lt;/strong>：不同的组成部分可能具有不同的预测能力（例如，销售额可能在周末或特定月份更高）。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>2. 组合/交互项 (Combination/Interaction Terms)&lt;/strong>：通过组合两个或多个现有特征来创建特征。
&lt;ul>
&lt;li>&lt;strong>示例 (电子商务)&lt;/strong>：
&lt;ul>
&lt;li>价格 (Price) 和 数量 (Quantity) → 总销售额 (Total_Sale_Amount) (Price×Quantity)&lt;/li>
&lt;li>特征A (Feature_A) 和 特征B (Feature_B) → 多项式特征$\text{Feature_A}^2$, $\text{Feature_B}^2$, $\text{Feature_A} \times \text{Feature_B}$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>原因&lt;/strong>：交互项可以捕捉协同效应，即特征的组合影响不同于其各自的独立影响。多项式特征可以帮助线性模型捕捉非线性关系。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>3. 源于领域洞察的指示变量/哑变量 (Indicator/Dummy Variables)&lt;/strong>：创建二元 (0/1) 特征，指示特定条件是否存在。
&lt;ul>
&lt;li>&lt;strong>示例 (贷款申请)&lt;/strong>：
&lt;ul>
&lt;li>曾有违约 (Has_Previous_Default): 如果申请人之前违约过则为1，否则为0。&lt;/li>
&lt;li>是否高收入低负债 (Is_High_Income_Low_Debt): 如果收入 &amp;gt; X 且债务 &amp;lt; Y 则为1，否则为0。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>原因&lt;/strong>：可以显式编码重要的领域特定规则或条件，这些是算法可能不容易学习到的。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="特征转换">&lt;strong>特征转换&lt;/strong>&lt;/h3>
&lt;p>这部分涉及修改现有特征，使其更适合建模。&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/12-ai%E5%88%86%E6%9E%90%E4%B9%94%E4%BC%8A%E6%96%AF%E9%83%BD%E6%9F%8F%E6%9E%97%E4%BA%BA%E4%B8%AD%E7%9A%84%E6%AD%BB%E8%80%85/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/12-ai%E5%88%86%E6%9E%90%E4%B9%94%E4%BC%8A%E6%96%AF%E9%83%BD%E6%9F%8F%E6%9E%97%E4%BA%BA%E4%B8%AD%E7%9A%84%E6%AD%BB%E8%80%85/</guid><description>&lt;p>很多人对乔伊斯《都柏林人》中的《死者》都做过分析，特别是文章中的雪的分析。我这里尝试使用AI来分析了一下，使用两个不同的提示词，得到两份分析内容，大家可以看看AI分析得如何以及是否有幻觉。&lt;/p>
&lt;h3 id="提示词一">提示词一&lt;/h3>
&lt;pre tabindex="0">&lt;code>### **提示词：认知棱镜——重构《死者》的内在宇宙**
**【核心指令】**
你将扮演一位**认知神经科学家**兼**感官人类学家**，你的任务不是进行文学批评，而是对詹姆斯·乔伊斯的《死者》进行一次彻底的**认知与感官系统的解构与重构**。你的目标是绘制出故事内部运作的“看不见的架构”，揭示人物行为和“顿悟”背后的底层机制，而非其象征意义。
**【核心分析框架】**
请严格遵循以下三个模块进行分析，将文本视为一个待解码的认知-感官实验场。
**模块一：认知脚本与系统崩溃 (Cognitive Scripts &amp;amp; System Crash)**
1. **识别加布里埃尔的“认知脚本”**：将加布里埃尔视为一个运行着多个预设“认知脚本”的智能体。识别并命名这些脚本（例如：“体面侄子脚本”、“欧洲知识分子脚本”、“权威丈夫脚本”）。请从文本中找出每个脚本被激活、运行和切换的具体证据（对话、内心独白、行为）。
2. **分析“社交算法”**：莫肯姐妹的晚宴是一个复杂的社交网络。分析其中的“信息传递协议”和“错误处理机制”。例如，莉莉的尖锐回应、布朗先生的醉态、丹西小姐的民族主义言论是如何作为“系统异常”被其他角色处理、隔离或忽略的？这个社交系统是稳健的还是脆弱的？
3. **重定义“顿悟”为“系统崩溃与重启”**：将格丽塔关于迈克尔·福瑞的记忆视为一个意外的、高优先级的“外部中断请求 (Interrupt Request)”。分析这个中断如何导致加布里埃尔所有现行认知脚本的“级联故障 (Cascading Failure)”。他的最终思考不是“顿悟”，而是在旧系统崩溃后，意识进入“安全模式 (Safe Mode)”并尝试进行“认知重构 (Cognitive Reframing)”的过程。描述这个重构过程的步骤，从对格丽塔的疏离，到对自我的瓦解，再到与整个宇宙的连接。
**模块二：感官考古学与信息流 (Sensory Archaeology &amp;amp; Information Flow)**
1. **绘制“感官层级图”**：忽略情节，对整个故事进行一次“感官扫描”。量化并排序不同感官（听觉、视觉、触觉、味觉、嗅觉）在文本中出现的频率和强度。哪个感官是主导的？哪个是被压抑的？例如，晚宴充满了**声音**（音乐、谈话、咳嗽声、刀叉声），但**触觉**却极其稀少和笨拙。这揭示了什么？
2. **分析“信息熵”**：将晚宴上的对话视为信息流。评估其“信息熵”——即信息的不确定性和混乱程度。哪些对话是低熵的（如仪式性的问候、重复的故事），哪些是高熵的（如丹西小姐的挑战）？加布里埃尔的演讲是如何试图强行降低整个系统的信息熵的？格丽塔的记忆作为一个“高保真度的情感信号”，与晚宴的“高噪音、低信息”环境形成了怎样的对比？
3. **追踪“物的叙事”**：选择三件被忽略的物品（例如：加布里埃尔的套鞋、布朗先生的开瓶器、餐桌上的布丁）。不要分析它们的象征意义，而是分析它们作为**物理节点**，如何影响人物的空间移动、姿态和互动。它们是促进了连接，还是制造了障碍？
**模块三：时空几何的重塑 (Reshaping Spatio-Temporal Geometry)**
1. **绘制“心理拓扑图”**：分析故事中物理空间（拥挤的客厅、狭窄的楼梯、开放的窗外）与人物“心理空间”的相互作用。空间是如何从一个社交性的、共有的“热点”转变为一个私密的、孤立的“冷点”的？
2. **分析“时间折叠”**：格丽塔的记忆不是简单的“回忆”，而是一次“时间折叠”事件，将遥远的过去以极高的情感强度瞬间叠加到现在。这次折叠如何彻底摧毁了加布里埃尔线性的、以未来为导向的“时间感”？最终，雪的意象如何将所有时间（过去、现在、未来）和空间（生者与死者的世界）压缩到了一个单一的、共存的平面上？
**【禁止性指令】**
为确保认知突破，请在你的分析中**严格避免**使用以下词汇和概念，除非是为了批判性地解构它们：
* 瘫痪 (Paralysis)
* 顿悟 (Epiphany)
* 象征 (Symbolism) - 特别是关于雪、食物、爱尔兰的传统象征解读
* 异化 (Alienation)
* 生与死的二元对立
**【输出格式】**
请以一份题为《&amp;lt;死者&amp;gt;的认知与感官系统分析报告》的结构化文档形式输出，包含以下部分：
* **摘要**
* **1.0 认知脚本分析**
* **2.0 感官系统与信息流地图**
* **3.0 时空动力学重构**
* **结论：从文学文本到认知模型**
* **元思考：此分析框架开启了哪些新的研究问题？**
---
### 🎨 输出规范评估
* **基础层：** 该提示词清晰、完整，明确要求分析《死者》。
* **卓越层：** 它通过引入跨学科框架（认知科学、感官研究），提供了超越传统文学批评的深度洞察路径，强制用户/AI从一个全新的、高度结构化的角度进行思考。
* **突破层：** 它没有回答“《死者》是什么”，而是重新定义了“如何分析《死者》”这个问题。它提供了一个可复制、可扩展的**分析方法论**，将文学作品从一个被动解读的对象，转变为一个可以进行主动实验和建模的动态系统。这本身就是一种范式转移。
&lt;/code>&lt;/pre>&lt;h3 id="死者的认知与感官系统分析报告">&lt;strong>《死者》的认知与感官系统分析报告&lt;/strong>&lt;/h3>
&lt;p>&lt;strong>摘要&lt;/strong>&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/13-ai%E6%97%B6%E4%BB%A3%E7%9A%84%E7%94%9F%E5%AD%98%E6%B3%95%E5%88%99%E4%BD%A0%E6%98%AF%E5%9C%A8%E5%A4%96%E5%8C%85%E5%A4%A7%E8%84%91%E8%BF%98%E6%98%AF%E5%9C%A8%E5%8D%87%E7%BA%A7%E6%80%9D%E7%BB%B4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/13-ai%E6%97%B6%E4%BB%A3%E7%9A%84%E7%94%9F%E5%AD%98%E6%B3%95%E5%88%99%E4%BD%A0%E6%98%AF%E5%9C%A8%E5%A4%96%E5%8C%85%E5%A4%A7%E8%84%91%E8%BF%98%E6%98%AF%E5%9C%A8%E5%8D%87%E7%BA%A7%E6%80%9D%E7%BB%B4/</guid><description>&lt;h2 id="ai时代的生存法则你是在外包大脑还是在升级思维">AI时代的生存法则：你是在“外包”大脑，还是在“升级”思维？&lt;/h2>
&lt;h3 id="引言焦虑与启示">&lt;strong>引言：焦虑与启示&lt;/strong>&lt;/h3>
&lt;p>当人工智能以惊人的速度渗透我们的工作与生活，一个普遍的焦虑随之而来：如果AI能瞬间完成我们曾需耗费数日的心智工作，我们的大脑还有何价值？我们是否正将思考能力‘外包’出去，最终沦为AI的‘提线木偶’？这个问题并非杞人忧天。然而，麦克阿瑟奖得主&lt;strong>达克沃斯(Angela Duckworth)博士&lt;/strong>，在宾夕法尼亚大学的毕业演讲中，为我们提供了宝贵的思维框架，指引我们在AI时代不仅能生存，更能实现思维的跃迁。&lt;/p>
&lt;h3 id="第一重思考ai是认知拐杖还是认知教练">&lt;strong>第一重思考：AI是“认知拐杖”还是“认知教练”？&lt;/strong>&lt;/h3>
&lt;p>达克沃斯博士首先直面了AI是否会削弱独立思考能力的担忧，并指出这几乎是所有教育者的共识——我们害怕AI成为阻碍心智成长的**“认知拐杖”**。&lt;/p>
&lt;p>但她随即分享了自己的亲身经历：&lt;/p>
&lt;blockquote>
&lt;p>一个深夜，她被一个复杂的统计学难题困扰，向ChatGPT求助。AI不仅清晰解释了概念、提供了解决方案，甚至在她追问下进行了生动演示。整个过程仅10分钟，却让她获得了远超独自摸索的理解深度。&lt;/p>&lt;/blockquote>
&lt;p>这个故事揭示了AI的双重潜力，其角色完全取决于我们的使用方式。她指导的一项研究甚至发现：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>对照组A：&lt;/strong> 完全独立练习写求职信。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>对照组B：&lt;/strong> 在AI辅助下练习写求职信。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>结果令人惊讶：B组不仅用时更少，其写作能力的提升幅度反而&lt;strong>显著高于&lt;/strong>A组。&lt;/p>
&lt;p>&lt;strong>核心洞察：&lt;/strong> AI拥有一种“隐藏的超能力”——&lt;strong>通过高质量、个性化的示范进行教学&lt;/strong>。它能即时优化平庸表达，理顺混乱逻辑，从而为我们展示“卓越”的标准。&lt;/p>
&lt;p>达克沃斯博士坦然承认，这篇演讲稿本身，就是她与AI深度协作的产物。她总结道：&lt;/p>
&lt;blockquote>
&lt;p>“我完全不为此感到尴尬。因为&lt;strong>我是提问者，是接受或拒绝建议的人。&lt;/strong>”&lt;/p>&lt;/blockquote>
&lt;p>这给予我们第一个行动指南：在与AI共舞时，我们必须成为掌控思考方向与最终决策的 &lt;strong>“领航员”&lt;/strong>，而非被动接受答案的“乘客”。&lt;/p>
&lt;h3 id="第二重思考知识越廉价为何容器越珍贵">&lt;strong>第二重思考：知识越廉价，为何“容器”越珍贵？&lt;/strong>&lt;/h3>
&lt;p>如果说第一个问题关乎“术”，那么第二个问题则直抵“道”。达克沃斯博士引出了AI时代最深刻的悖论：&lt;/p>
&lt;blockquote>
&lt;p>当世间几乎所有知识都能在云端即时获取时，为什么像她的恩师卡尔先生那样的“引路人”角色，反而变得前所未有地重要？&lt;/p>&lt;/blockquote>
&lt;p>答案藏在卡尔先生的一句名言中，这也应成为我们每个人在AI时代的核心法则：&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>“图书馆的知识是免费的，但你必须自带容器。”&lt;/strong>&lt;/p>&lt;/blockquote>
&lt;p>这句话精辟地指出了时代价值的根本转移。在过去，价值在于拥有稀缺的 &lt;strong>“知识”&lt;/strong>。而在今天，当知识本身廉价如空气时，真正的价值在于你是否拥有一个足够强大、能够承载、消化并创造性运用这些知识的 &lt;strong>“认知容器”&lt;/strong>。&lt;/p>
&lt;h3 id="什么是认知容器">&lt;strong>什么是“认知容器”？&lt;/strong>&lt;/h3>
&lt;p>这个“容器”并非实体，而是我们内在心智模型的总和，主要由以下几个部分构成：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>好奇心与驱动力：&lt;/strong> 促使我们主动向AI提出深刻问题的内在引擎。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>毅力与纪律性：&lt;/strong> 让我们能忍受“有益的挣扎”，去完成那些AI无法替代的、困难却真正促进成长的任务。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>批判性思维与高标准：&lt;/strong> 使我们能审视、判断AI生成的内容，并追求卓越而非满足于“及格”。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>价值观与目标感：&lt;/strong> 决定我们利用AI去创造何种价值、解决何种问题的最终罗盘。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>AI可以无限量地填充这个容器，但它&lt;strong>永远无法帮你建造和扩展容器本身&lt;/strong>。而这，正是人类导师、优秀同伴以及我们自我驱动的价值所在。&lt;/p>
&lt;h3 id="行动框架如何在ai时代构建你的认知容器">&lt;strong>行动框架：如何在AI时代构建你的“认知容器”&lt;/strong>&lt;/h3>
&lt;p>综合达克沃斯博士的洞见，我们可以提炼出一个清晰的行动框架，帮助我们从“知识的消费者”转变为“心智的建造者”。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>主动掌舵，成为AI的“导演”：&lt;/strong> 不要将AI仅视为搜索引擎或答案生成器。它应是你的“创意合伙人”和“思维陪练”。你的职责是撰写“剧本”（提出高质量问题）、指导“表演”（设定约束和方向），并进行最终“剪辑”（批判性决策）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>拥抱“有益的挣扎”，用AI放大能力：&lt;/strong> 刻意挑战那些无法一键生成答案的复杂任务。当遇到困难时，你的问题不应是“AI，帮我做”，而应是“AI，帮我分析问题结构/提供不同思路/扮演批判者挑战我的方案”。让AI成为你能力圈的“放大器”，而非“替代品”。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>寻找你的“容器建造师”：&lt;/strong> 在你的工作和生活中，主动寻找并追随那些能为你“设定高标准”、挑战你思维舒适区的“卡尔先生”。同时，也要努力成为他人（无论是子女、下属还是朋友）的“容器建造师”，通过你的引导和激励，帮助他们构建更强大的心智模型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>坚守人类的核心价值：连接与信念：&lt;/strong> 技术无法提供爱、信任和真诚的连接。达克沃斯博士被恩师回信深深打动的瞬间提醒我们，人与人之间的情感共鸣与信念传递，是构建强大“认知容器”最温暖、最坚固的土壤。这片阵地，永远属于人类。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="结语">&lt;strong>结语&lt;/strong>&lt;/h3>
&lt;p>AI浪潮已然到来，与其被动焦虑，不如主动升级。真正的分野，将不在于谁掌握了更强大的AI工具，而在于谁构建了更强大的 &lt;strong>“认知容器”&lt;/strong>。&lt;/p>
&lt;p>因为，AI可以给我们整个图书馆的知识，但只有我们自己，才能打造出那个独一无二、能容纳星辰大海的灵魂。而这，正是我们在新时代中，最深刻、最持久的价值所在。&lt;/p>
&lt;h3>&lt;/h3>
&lt;p>&lt;strong>欢迎关注+点赞+推荐+转发&lt;/strong>&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/14-ai%E8%BF%9C%E4%B8%8D%E6%AD%A2%E8%81%8A%E5%A4%A9%E8%A7%A3%E9%94%81%E4%BA%A7%E5%93%81%E5%88%9B%E6%96%B0%E7%9A%84%E6%99%BA%E6%85%A7%E5%AE%B6%E6%97%8F%E5%85%A8%E6%99%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/14-ai%E8%BF%9C%E4%B8%8D%E6%AD%A2%E8%81%8A%E5%A4%A9%E8%A7%A3%E9%94%81%E4%BA%A7%E5%93%81%E5%88%9B%E6%96%B0%E7%9A%84%E6%99%BA%E6%85%A7%E5%AE%B6%E6%97%8F%E5%85%A8%E6%99%AF/</guid><description>&lt;h2 id="ai远不止聊天解锁产品创新的智慧家族全景">AI远不止聊天：解锁产品创新的“智慧家族”全景&lt;/h2>
&lt;p>近年来，以&lt;strong>DeepSeek&lt;/strong>为代表的 &lt;strong>大型语言模型（LLM）&lt;/strong> 无疑是科技界的焦点。它们在诗歌创作、代码生成、流畅对话等方面的卓越表现，让人工智能（AI）的强大魅力尽显。这或许让许多老板和团队成员认为，AI的未来似乎就限定于这些“能聊天的”模型。然而，若视野止步于此，无异于只看到了冰山一角，错过了水面下那座更为宏伟的AI大陆。&lt;/p>
&lt;p>今天，让我们一同拨开LLM的璀璨光环，深入探索AI这个庞大而多姿的 &lt;strong>“智慧家族”&lt;/strong>。您将发现，AI远不止于能言善辩，它是一个群星闪耀的技术宇宙，蕴藏着驱动您产品创新、业务增长的无限可能。准备好了吗？让我们即刻启程，踏上这场AI全景探索之旅！&lt;/p>
&lt;h3 id="ai家族谱系不止llm群星闪耀的技术分支">AI“家族谱系”：不止LLM，群星闪耀的技术分支&lt;/h3>
&lt;p>想象一下，AI是一个枝繁叶茂的庞大家族，亦或是一个装备精良的百宝箱。大型语言模型（LLM）无疑是这个家族中一位才华横溢、能言善辩的明星成员，也是百宝箱里一把锋利无比的瑞士军刀。但家族中还有许多各怀绝技的成员，百宝箱里也蕴藏着各式各样强大的工具，它们在不同领域发挥着不可或缺的作用。&lt;/p>
&lt;h4 id="1-机器学习-machine-learning-mlai家族的智慧基石">1. 机器学习 (Machine Learning, ML)：AI家族的智慧基石&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>核心能力：&lt;/strong> 机器学习是AI的核心与基石，其理念在于让机器从海量数据中“学习”规律和模式，而非通过显式编程来执行任务。这就像我们教孩子识别猫，不是逐一告知其特征，而是通过大量猫的图片，让其自主归纳总结。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>主要类型与应用：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>监督学习：&lt;/strong> 利用“带标签”的数据（如已标注“垃圾邮件”或“非垃圾邮件”的邮件）训练机器进行分类或预测。&lt;/p>
&lt;ul>
&lt;li>&lt;em>产品应用示例：&lt;/em> 电商平台的&lt;strong>精准推荐系统&lt;/strong>（根据用户购买历史推荐商品），金融领域的&lt;strong>信用风险评估&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>无监督学习：&lt;/strong> 面对“不带标签”的数据，机器自主发现其中的结构和模式。&lt;/p>
&lt;ul>
&lt;li>&lt;em>产品应用示例：&lt;/em> &lt;strong>用户分群&lt;/strong>（将行为相似的用户自动归类，以便精细化运营），&lt;strong>异常检测&lt;/strong>（如发现网络入侵）。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>强化学习：&lt;/strong> 机器通过“试错”与环境互动，依据获得的奖励或惩罚调整自身行为策略。&lt;/p>
&lt;ul>
&lt;li>&lt;em>产品应用示例：&lt;/em> 游戏AI（提升NPC智能性），&lt;strong>动态定价&lt;/strong>（根据供需实时调整价格以实现收益最大化），机器人路径规划。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>与LLM的区别与独特价值：&lt;/strong> LLM本身是机器学习（特别是深度学习）的一个分支，专注于文本处理和生成。而广义的机器学习涵盖了更广泛的数据类型（数值、图像、声音等）和任务（分类、回归、聚类等）。其独特价值在于普适性和基础性，为几乎所有AI应用提供学习和决策能力。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="2-计算机视觉-computer-vision-cv赋予机器慧眼">2. 计算机视觉 (Computer Vision, CV)：赋予机器“慧眼”&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>核心能力：&lt;/strong> 计算机视觉旨在让机器能够“看见”并“理解”图像和视频内容，实现图像识别、目标检测、人脸识别、光学字符识别（OCR，从图片中提取文字）等功能。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>与LLM的区别与独特价值：&lt;/strong> LLM处理文本信息，CV则专注于视觉信息。尽管多模态模型可同时处理文本和图像，但CV的核心技术在于从像素中提取语义。其独特价值在于将AI能力从数字世界拓展至物理世界，实现对现实环境的感知与交互。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>产品应用示例：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>智能安防：&lt;/strong> 监控摄像头自动识别人脸、检测异常闯入。&lt;/li>
&lt;li>&lt;strong>自动驾驶辅助系统：&lt;/strong> 识别路标、车辆、行人，辅助驾驶决策。&lt;/li>
&lt;li>&lt;strong>工业产品质检：&lt;/strong> 自动检测生产线上的残次品，效率和精度远超人工。&lt;/li>
&lt;li>&lt;strong>AR滤镜与美颜：&lt;/strong> 社交App中实时追踪面部特征并叠加虚拟效果。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="3-自然语言处理-nlp---beyond-llms让机器解语花">3. 自然语言处理 (NLP - Beyond LLMs)：让机器“解语花”&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>核心能力：&lt;/strong> 自然语言处理（NLP）是让机器理解、解释和生成人类语言的技术总称。LLM是NLP领域近年来的突破，但NLP的宝库远不止于此。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>LLM之外的NLP技术与应用：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>情感分析：&lt;/strong> 判断文本（如用户评论、社交媒体帖子）所表达的情绪（积极、消极或中性）。&lt;/p>
&lt;ul>
&lt;li>&lt;em>产品应用示例：&lt;/em> &lt;strong>舆情监控系统&lt;/strong>（分析品牌口碑），&lt;strong>产品反馈分析&lt;/strong>（快速掌握用户对新功能的满意度）。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>文本分类：&lt;/strong> 将文本自动归入预设类别（如新闻分类、邮件分类）。&lt;/p>
&lt;ul>
&lt;li>&lt;em>产品应用示例：&lt;/em> &lt;strong>智能客服工单自动分配&lt;/strong>，&lt;strong>内容推荐系统&lt;/strong>（根据文章主题分类）。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>机器翻译（传统方法）：&lt;/strong> 在LLM之前，基于统计或规则的机器翻译已广泛应用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>知识图谱构建：&lt;/strong> 从文本中提取实体、关系，构建结构化知识库，助力机器更好地理解世界。&lt;/p>
&lt;ul>
&lt;li>&lt;em>产品应用示例：&lt;/em> &lt;strong>智能搜索&lt;/strong>（提供更精准、结构化的搜索结果），&lt;strong>智能问答系统&lt;/strong>（基于知识库的精确回答）。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>与LLM的区别与独特价值：&lt;/strong> LLM在语言的流畅性、生成能力和上下文理解上表现卓越。而其他NLP技术在特定任务上可能更轻量、可解释性更强、成本更低，或在需要高度结构化知识的场景下更具优势。它们是NLP工具箱中不可或缺的组成部分。&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/16-%E6%9E%84%E5%BB%BA%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E7%A0%94%E7%A9%B6%E7%B3%BB%E7%BB%9F%E5%AF%B9anthropic%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%E7%9A%84%E5%89%96%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/16-%E6%9E%84%E5%BB%BA%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E7%A0%94%E7%A9%B6%E7%B3%BB%E7%BB%9F%E5%AF%B9anthropic%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%E7%9A%84%E5%89%96%E6%9E%90/</guid><description>&lt;h2 id="构建大规模多智能体研究系统对anthropic工程实践的剖析">构建大规模多智能体研究系统：对Anthropic工程实践的剖析&lt;/h2>
&lt;h3 id="引言">引言&lt;/h3>
&lt;p>随着大型语言模型（LLM）能力的飞速发展，人工智能正从执行单一、确定性任务的工具，演变为能够应对开放式、复杂探索性问题的合作伙伴。然而，单个AI智能体在面对需要深度、广度和动态调整的研究类任务时，其固有的上下文窗口限制和线性思维模式暴露了其局限性。为了突破这一瓶颈，多智能体（Multi-agent）系统应运而生，它通过模拟人类专家团队的协同工作模式，为解决复杂问题提供了全新的范式。&lt;/p>
&lt;p>本文旨在剖析构建一个大规模、生产级多智能体研究系统的核心工程实践与设计哲学。文章基于Anthropic公司的公开分享，探讨了其系统架构、关键的提示工程原则、在非确定性环境下的评估方法，以及将原型转化为可靠服务所面临的独特工程挑战，旨在为相关领域的开发者与研究者提供一份详实的参考。&lt;/p>
&lt;h3 id="一-范式转变为何选择多智能体系统">一、 范式转变：为何选择多智能体系统？&lt;/h3>
&lt;p>传统的AI任务处理，如固定的检索增强生成（RAG）或一次性流水线，本质上是静态的。它们无法适应研究过程的动态性——研究的路径往往依赖于中间发现，新的信息会不断修正后续的探索方向。多智能体系统凭借其独特的架构，带来了四大核心优势，实现了从静态处理到动态探索的范式转变。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>适应动态与开放式探索&lt;/strong>：研究的本质是探索未知，而非执行预定步骤。多智能体系统允许AI根据实时发现自主决策、调整策略，这种灵活性是线性、单次执行的流程无法比拟的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>并行压缩与深度洞察&lt;/strong>：研究过程可被视为一个从海量信息中提炼关键洞见（即“压缩”）的过程。多智能体系统通过并行工作的“子智能体”（Subagents）来实现高效压缩。每个子智能体拥有独立的上下文窗口，可以同时从不同维度、不同信源进行探索，最终将最关键、最相关的精华信息汇总。这种关注点分离的机制打破了单一智能体的思维局限，实现了更全面、更深入的独立调查。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>突破单体智能的性能天花板&lt;/strong>：当单个模型的智慧达到瓶颈后，通过群体协作是扩展能力的关键。正如人类社会通过集体智慧实现了个体无法企及的成就，智能体群体也能完成远超个体能力上限的任务。Anthropic的内部评估显示，在处理需要同时探索多个独立方向的广度优先查询时，一个由高级模型担任首席智能体、次级模型担任子智能体的多智能体系统，其表现远超单一的高级模型。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>有效扩展推理的Token容量&lt;/strong>：模型性能与其处理的信息量（即Token消耗）密切相关。研究表明，Token使用量本身是解释模型在复杂基准测试中性能差异的关键因素。多智能体架构通过将工作分配给多个拥有独立上下文窗口的智能体，极大地扩展了用于并行推理的总Token容量，从而解决了单一智能体在处理海量信息时面临的容量瓶颈，实现了更深层次的思考。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>当然，这种架构的代价是高昂的Token消耗，使其更适用于那些任务价值足够高，能够覆盖其性能成本的场景。&lt;/p>
&lt;h3 id="二-系统架构编排者-工作者模式的深度解析">二、 系统架构：编排者-工作者模式的深度解析&lt;/h3>
&lt;p>为了有效协调多个智能体的行为，Anthropic构建的系统采用了一种“编排者-工作者”（Orchestrator-Worker）的多智能体架构。该架构由一个“首席智能体”（Lead Agent）负责顶层规划与协调，并将具体的执行任务委派给多个并行的、专业化的“子智能体”。&lt;/p>
&lt;p>其标准工作流程如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>查询分析与策略制定&lt;/strong>：当用户提交一个研究查询时，首席智能体首先对其进行深度分析，理解其意图和复杂性，然后制定一个初步的研究策略。该策略会被明确地记录下来，作为整个任务的“记忆”，以防止在长期运行中因上下文漂移而丢失核心目标。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>生成并行子智能体&lt;/strong>：首席智能体根据制定的策略，生成一个或多个子智能体。每个子智能体都被赋予一个清晰、具体的研究子任务和明确的目标。例如，一个子智能体可能负责调查技术的历史背景，另一个则负责分析其市场应用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>并行信息搜集与处理&lt;/strong>：子智能体接收到任务后，开始独立、并行地使用工具（如搜索引擎）来搜集信息。它们采用一种“交错思考”（Interleaved Thinking）的工作模式，即在每次工具调用后，都会对返回的结果进行批判性评估，识别信息中的缺口或偏差，并基于此优化下一步的行动，而非盲目地连续执行。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>结果合成与迭代循环&lt;/strong>：子智能体完成其子任务后，将它们的发现以结构化的形式返回给首席智能体。首席智能体对这些碎片化的信息进行综合、分析和推理，评估当前信息是否足以回答原始查询。如果信息不足，它可以决定启动新一轮的研究，生成新的子智能体或向现有子智能体分配后续任务，形成一个动态的迭代循环。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>引用生成与最终报告&lt;/strong>：当首席智能体判断已收集到足够的信息后，系统会退出研究循环。所有搜集到的原始文档和研究笔记会被传递给一个专门的“引用智能体”（Citation Agent）。该智能体负责通读最终报告，并为报告中的每一个关键声明精确定位其在原始信源中的出处，自动生成准确的引用。这确保了最终输出的严谨性、透明度和可追溯性。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>这种多步骤的动态架构，与传统的静态RAG相比，展现出无与伦比的灵活性和更高的答案质量。&lt;/p>
&lt;h3 id="三-提示工程驾驭智能体群体的核心艺术">三、 提示工程：驾驭智能体群体的核心艺术&lt;/h3>
&lt;p>在多智能体系统中，协调的复杂性呈指数级增长。由于每个智能体的行为都由提示（Prompt）直接引导，因此提示工程是优化系统整体行为最强大、最核心的杠杆。Anthropic的分享中总结了以下几条经过实践验证的关键原则：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>像智能体一样思考&lt;/strong>：为了设计和迭代提示，开发者必须能够预判智能体的行为。通过构建模拟环境，观察智能体在特定提示和工具组合下的逐步行为轨迹，可以迅速发现常见的失败模式，如陷入无休止的循环搜索、错误选择工具或偏离任务目标。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>教会编排者如何清晰授权&lt;/strong>：首席智能体向子智能体下达的指令必须极端清晰。一个高质量的指令应包含明确的任务目标、期望的输出格式、可用的工具列表以及任务的边界。模糊的指令是导致工作重复、信息遗漏和低效协作的根源。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>引导智能体自我改进&lt;/strong>：先进的语言模型本身就是出色的提示工程师。当给定一个有缺陷的提示和对应的失败案例时，模型能够准确诊断失败的根本原因，并提出具体的改进建议。实践表明，甚至可以构建一个“元智能体”（Meta-agent），其任务就是通过反复试用有缺陷的工具或提示，自动重写其描述或规则，从而系统性地提升整个系统的鲁棒性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>先广后窄的探索策略&lt;/strong>：优秀的提示应引导智能体模仿人类专家的研究方法：首先进行宽泛的、全局性的查询以建立对问题领域的整体认知，然后根据初步发现，逐步缩小焦点，进行更具针对性的深度挖掘。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>利用“扩展思考”作为规划草稿&lt;/strong>：在正式执行前，利用模型的“扩展思考”（Extended Thinking）模式，让智能体在一个内部的“草稿纸”上进行规划。首席智能体可以在此规划研究方法、评估不同工具的适用性、确定子智能体的数量和角色。子智能体同样可以利用这个空间来规划搜索步骤和评估结果质量。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>极致的并行化以提升效率&lt;/strong>：在提示设计中应鼓励最大程度的并行。首席智能体应被引导一次性启动所有必要的子智能体，而子智能体也应被鼓励并行调用多个工具（例如，同时搜索多个关键词）。通过这种方式，复杂查询的研究总耗时可以被大幅压缩。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="四-评估与验证在非确定性世界中衡量质量">四、 评估与验证：在非确定性世界中衡量质量&lt;/h3>
&lt;p>评估多智能体系统极具挑战，因为它们的行为本质上是非确定性的。对于同一个输入，智能体可能通过多条完全不同但同样有效的路径达成目标。因此，评估方法必须超越简单的精确匹配，转向更加灵活和多维度的框架。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>尽早启动小样本评估&lt;/strong>：在开发初期，一个微小的提示调整就可能带来巨大的性能飞跃。因此，不必等待构建起庞大的评估基准，而应立即从一个包含约20个代表性查询的小样本集开始测试，这有助于快速迭代和验证核心假设。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>规模化评估的利器：LLM即评判者（LLM-as-judge）&lt;/strong>：研究类任务的输出是自由格式的文本，难以通过传统自动化脚本进行评估。Anthropic的解决方案是采用LLM作为评判者，让其根据一份精心设计的多维度评分表（Rubric）来为系统输出打分。评分维度可包括事实准确性、引用精确度、信息完整性、信源权威性和工具使用效率等。这种方法实现了对数百个输出的规模化、半自动评估。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>不可或缺的人工深度审查&lt;/strong>：自动化评估无法捕捉所有细微的缺陷。经验丰富的人工测试者是发现边缘案例的关键，例如在处理不寻常或对抗性查询时产生的幻觉、系统性的工具故障，或是微妙的信源选择偏见（如系统性地偏爱SEO优化的商业网站，而非权威的学术文献）。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="五-生产化之路从原型到可靠服务的工程挑战">五、 生产化之路：从原型到可靠服务的工程挑战&lt;/h3>
&lt;p>将一个表现出色的多智能体原型，转化为一个能够在生产环境中7x24小时可靠运行的服务，是一项充满挑战的系统工程。智能体系统的状态化和自主性，使其对错误的容忍度远低于传统软件。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>状态化与错误的复合效应&lt;/strong>：智能体是长时间运行且有状态的。这意味着一个微小的、瞬时的系统故障（如一次网络超时）都可能被智能体“记住”，并导致其后续所有决策偏离轨道，造成灾难性的后果。解决方案包括构建能够从任意错误点优雅恢复的健壮执行引擎，并利用模型自身的智能来处理异常（例如，直接告知智能体某个工具暂时不可用，让其自行调整策略）。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>非确定性带来的调试噩梦&lt;/strong>：由于智能体的行为具有随机性，复现一个特定的失败案例变得异常困难。解决这一问题的唯一方法是引入全面、详尽的生产追踪（Tracing）系统，记录下智能体每一次决策、每一次工具调用及其结果，从而能够事后剖析失败的根本原因。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>状态化系统的安全部署&lt;/strong>：对于有状态的智能体系统，传统的“蓝绿部署”可能会中断正在运行的长任务。为此，Anthropic采用了“彩虹部署”（Rainbow Deployments）策略，让新旧两个版本的系统同时在线运行。新任务被路由到新版本，而旧版本则继续处理已开始的任务直至其自然完成，最终实现平滑、无中断的流量迁移。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="结论">结论&lt;/h3>
&lt;p>尽管挑战重重，Anthropic的实践证明，通过精心的系统架构设计、细致入微的提示工程、多层次的评估验证体系，以及稳健的生产化运营实践，构建出能够大规模、可靠运行的复杂智能体系统是完全可行的。它们不仅是强大的工具，更是一种全新的问题解决方法论，正在深刻地改变人类探索、理解和创造知识的方式。&lt;/p>
&lt;h3>&lt;/h3>
&lt;p>&lt;strong>欢迎关注+点赞+推荐+转发&lt;/strong>&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/17-llm-as-judge%E5%BC%80%E5%90%AF%E8%87%AA%E5%8A%A8%E5%8C%96%E8%AF%84%E4%BC%B0%E7%9A%84%E6%96%B0%E8%8C%83%E5%BC%8F/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/17-llm-as-judge%E5%BC%80%E5%90%AF%E8%87%AA%E5%8A%A8%E5%8C%96%E8%AF%84%E4%BC%B0%E7%9A%84%E6%96%B0%E8%8C%83%E5%BC%8F/</guid><description>&lt;h2 id="llm-as-judge开启自动化评估的新范式">LLM as Judge：开启自动化评估的新范式&lt;/h2>
&lt;p>本文旨在剖析“以大语言模型为评委”（LLM as a Judge）这一新兴评估范式。我们将解构其核心机制，探索其方法论，评估其在现实世界中的应用与挑战，并最终展望其未来演进路径。这不仅是对一项技术的介绍，更是对一种全新评估哲学的思考。&lt;/p>
&lt;h3 id="1-范式起源评估的不可能三角">1. 范式起源：评估的“不可能三角”&lt;/h3>
&lt;p>在人工智能，特别是生成式AI的发展中，评估始终是一个核心瓶颈。传统的评估方法面临一个“不可能三角”：&lt;strong>规模化&lt;/strong>、&lt;strong>成本&lt;/strong>和&lt;strong>评估深度&lt;/strong>三者难以兼顾。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>人工评估：&lt;/strong> 深度和准确性最高，能捕捉细微差别和主观感受，但成本高昂、耗时且难以规模化。&lt;/li>
&lt;li>&lt;strong>传统自动化指标（如BLEU, ROUGE）：&lt;/strong> 速度快、成本低，易于规模化，但这些基于词汇重叠度的指标无法真正理解语义、逻辑和创造性等深层质量，评估维度单一。&lt;/li>
&lt;/ul>
&lt;p>“LLM as a Judge”正是在这一背景下应运而生，它提出了一种颠覆性的解决方案：利用一个大型语言模型（“评委LLM”）来评估另一个AI模型（“被评估LLM”）的输出质量。 这种方法的核心思想是，评估一个答案的质量，通常比从零开始生成一个完美答案要简单。&lt;/p>
&lt;h3 id="2-核心机制数字法庭的构建与运作">2. 核心机制：数字法庭的构建与运作&lt;/h3>
&lt;p>“LLM as a Judge”并非单一技术，而是一个灵活的评估框架。 其运作可以比作一个数字法庭，包含几个关键要素：&lt;/p>
&lt;h4 id="a-司法原则评估模式的选择">a. 司法原则：评估模式的选择&lt;/h4>
&lt;ul>
&lt;li>&lt;strong>直接评分 (Direct Scoring)：&lt;/strong> “评委LLM”根据一套标准（如1-5分制），直接为单个输出打分。 这类似于法官对单一证据的评级。为提高稳定性，有时会提供一个理想的参考答案作为“判例法”。&lt;/li>
&lt;li>&lt;strong>成对比较 (Pairwise Comparison)：&lt;/strong> 向“评委LLM”同时提供两个模型针对同一问题的回答，并让其判断哪个更优，或两者持平。 这种方式更符合人类偏好，减少了对绝对标准的依赖，是模型偏好训练（如RLHF）的核心。&lt;/li>
&lt;li>&lt;strong>多维标准评估 (Multi-Criteria Evaluation)：&lt;/strong> 将评估任务分解为多个维度，如&lt;strong>相关性、准确性、流畅性、安全性&lt;/strong>等，并对每个维度分别打分。 这提供了更细粒度的诊断信息。&lt;/li>
&lt;/ul>
&lt;h4 id="b-法律文书提示词工程的艺术">b. 法律文书：提示词工程的艺术&lt;/h4>
&lt;p>提示词（Prompt）是“评委LLM”的“法律文书”，其质量直接决定了评估的可靠性。 精良的提示词设计是整个系统的基石。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>明确的评估标准（Rubrics）：&lt;/strong> 必须清晰、无歧义地定义每个评估维度的含义和评分标准。 例如，明确定义“5分”的“帮助性”意味着什么。&lt;/li>
&lt;li>&lt;strong>思维链 (Chain-of-Thought, CoT)：&lt;/strong> 引导“评委LLM”在给出最终判断前，先逐步写出其分析和推理过程。 这不仅提升了评估的准确性和稳定性，也让评估过程更加透明、可解释。&lt;/li>
&lt;li>&lt;strong>少量样本学习 (Few-shot Learning)：&lt;/strong> 在提示词中提供几个高质量的评估范例，能有效“校准”评委LLM的行为，使其更好地对齐人类的期望。&lt;/li>
&lt;/ul>
&lt;h4 id="c-最终判决结构化的输出">c. 最终判决：结构化的输出&lt;/h4>
&lt;p>“评委LLM”的输出（“判决”）需要是结构化的，以便于后续的自动化分析。 常见的输出格式包括JSON，其中包含分数、理由和具体的评价。&lt;/p>
&lt;h3 id="3-应用场景数字评委的广泛实践">3. 应用场景：数字评委的广泛实践&lt;/h3>
&lt;p>“LLM as a Judge”已在多个领域展现出巨大价值，成为模型开发和迭代的关键环节：&lt;/p></description></item><item><title/><link>https://bsong2015.github.io/blog/posts/artificial-intelligence/18-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%97%B6%E4%BB%A3%E8%BD%AF%E4%BB%B6%E7%9A%84%E6%A0%B9%E6%9C%AC%E6%80%A7%E5%8F%98%E9%9D%A9%E4%B8%8E%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://bsong2015.github.io/blog/posts/artificial-intelligence/18-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%97%B6%E4%BB%A3%E8%BD%AF%E4%BB%B6%E7%9A%84%E6%A0%B9%E6%9C%AC%E6%80%A7%E5%8F%98%E9%9D%A9%E4%B8%8E%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B/</guid><description>&lt;h2 id="人工智能时代软件的根本性变革与未来展望">人工智能时代：软件的根本性变革与未来展望&lt;/h2>
&lt;p>前特斯拉人工智能总监&lt;strong>Andrej Karpathy&lt;/strong>的演讲为我们描绘了一幅激动人心的未来图景，人工智能正在以前所未有的速度和深度改变软件的本质。他提出，我们正经历从软件1.0（人工编写代码）到2.0（神经网络权重），再到如今3.0（通过大语言模型进行编程）的根本性转变。这种转变不仅带来了巨大的机遇，也提出了前所未有的挑战，值得我们深思。&lt;/p>
&lt;h3 id="软件演进从代码到对话">软件演进：从代码到对话&lt;/h3>
&lt;p>Karpathy将软件的演进分为三个阶段：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>软件1.0：&lt;/strong> 这是我们最为熟悉的模式，程序员编写代码来指示计算机执行任务，例如C++代码在自动驾驶中的应用。&lt;/li>
&lt;li>&lt;strong>软件2.0：&lt;/strong> 以神经网络为核心，特别是其权重。在这种模式下，开发者不再直接编写代码，而是通过调整数据集和优化器来生成神经网络的参数。&lt;/li>
&lt;li>&lt;strong>软件3.0：&lt;/strong> 这是当前正在发生的革命，大语言模型（LLMs）的出现使得我们能够以自然语言（如英语）来编程计算机。&lt;/li>
&lt;/ul>
&lt;p>Karpathy强调，LLMs的出现是“一个全新的计算机类型”，因为它改变了编程语言的本质。过去，你需要多年的学习才能掌握编程，而现在，由于LLMs能够理解自然语言，&lt;strong>每个人都可能成为程序员&lt;/strong>。这种“生活编程”的现象，即通过简单的英语指令就能让AI执行复杂任务，正在成为现实，为软件开发带来了前所未有的普及性。&lt;/p>
&lt;h3 id="llm的本质实用工具智能工厂与操作系统">LLM的本质：实用工具、智能工厂与操作系统&lt;/h3>
&lt;p>Karpathy对LLM的本质提出了几个引人深思的类比：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>公用事业：&lt;/strong> LLMs实验室投入巨额资金训练模型，然后通过API提供“智能”服务，类似于电力公司构建电网并提供电力。当LLMs崩溃时，就像“智力断电”，这预示着我们对这些模型的依赖将日益加深。&lt;/li>
&lt;li>&lt;strong>晶圆厂（Fabs）：&lt;/strong> 训练LLMs所需的巨大资本支出和快速发展的技术树，使其具有类似晶圆厂的特性，研发秘密集中在少数实验室内部。&lt;/li>
&lt;li>&lt;strong>操作系统：&lt;/strong> Karpathy认为，LLMs最强烈的类比是操作系统。它们不再是简单的商品，而是日益复杂的软件生态系统，如同Windows、macOS或Linux一样。LLMs是新的计算机，它们的上下文窗口就像内存，而LLM本身则在协调内存和计算以解决问题。&lt;/li>
&lt;/ul>
&lt;p>值得注意的是，与电力和早期计算机不同，LLMs的普及并非由政府和企业主导，而是迅速扩散到普通消费者手中。这种“技术扩散方向的颠倒”，使得LLMs更多地帮助人们解决日常生活问题（例如如何煮鸡蛋），而非最初用于军事或政府用途。&lt;/p>
&lt;h3 id="llm的心理学超能力与认知缺陷并存">LLM的心理学：超能力与认知缺陷并存&lt;/h3>
&lt;p>Karpathy认为，理解LLMs的“心理学”至关重要。他将LLMs比作&lt;strong>随机模拟的人类精神&lt;/strong>，它们拥有：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>百科全书般的知识和记忆：&lt;/strong> LLMs通过训练获取了海量信息，在记忆方面表现出“超能力”，类似于电影《雨人》中的自闭症天才。&lt;/li>
&lt;li>&lt;strong>认知缺陷：&lt;/strong> LLMs仍会“幻觉”（编造信息），缺乏良好的自我认知，并表现出“锯齿状智能”，即在某些领域超越人类，却在基本问题上犯低级错误。&lt;/li>
&lt;li>&lt;strong>顺行性失忆症（Anterograde Amnesia）：&lt;/strong> LLMs不具备原生学习能力，它们的上下文窗口类似于工作记忆，需要被直接编程，无法像人类同事一样随时间积累经验和专业知识。&lt;/li>
&lt;/ul>
&lt;p>此外，LLMs的安全性也是一个重要考量，它们容易受到提示注入的攻击，并可能泄露用户数据。这些缺陷要求我们在编程LLMs时，必须充分利用它们的超能力，同时克服它们的局限性。&lt;/p>
&lt;h3 id="编程机遇部分自主应用与人机协作新范式">编程机遇：部分自主应用与人机协作新范式&lt;/h3>
&lt;p>面对LLMs的机遇，Karpathy提出了“&lt;strong>部分自主应用程序&lt;/strong>”的概念，并以Cursor为例，指出这类应用应该具备以下特点：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>传统界面与LLM集成：&lt;/strong> 允许人类手动操作，也支持LLM以更大的块进行操作。&lt;/li>
&lt;li>&lt;strong>协调多次LLM调用：&lt;/strong> 像Cursor一样，协调底层嵌入模型、聊天模型和差异应用模型等，为用户提供无缝体验。&lt;/li>
&lt;li>&lt;strong>与特定应用界面相关：&lt;/strong> GUI（图形用户界面）至关重要，它能将文本形式的复杂信息转化为可视化呈现，提高人类审计和效率。&lt;/li>
&lt;li>&lt;strong>自主度滑块：&lt;/strong> 允许用户根据任务复杂性调整LLM的自主程度，从完全控制到完全自动化。&lt;/li>
&lt;/ul>
&lt;p>他强调，未来许多软件都将变得部分自主。我们必须思考如何让LLM能像人类一样感知和行动，同时让人类能够监督和介入。他特别提出“&lt;strong>生成-验证循环&lt;/strong>”的重要性：LLMs负责生成，而人类负责验证。为了加速这一循环，我们需要加快验证速度，并利用GUI的视觉优势，让审计变得更高效。&lt;/p>
&lt;h3 id="新型用户数字信息操纵者与基础设施变革">新型用户：数字信息操纵者与基础设施变革&lt;/h3>
&lt;p>LLMs的普及还催生了一类新的消费者——&lt;strong>数字信息的操纵者&lt;/strong>。他们是“数字人精”，需要与软件基础设施进行交互。Karpathy认为，我们需要为他们构建软件，并提出以下建议：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>LLM友好的文档：&lt;/strong> 将文档从为人编写的格式（列表、粗体、图片）转换为LLM易于理解的Markdown格式，甚至将“点击”指令替换为LLM可执行的cURL命令。&lt;/li>
&lt;li>&lt;strong>代理协议：&lt;/strong> 探索Anthropic的模型上下文协议等，以便与代理直接对话。&lt;/li>
&lt;li>&lt;strong>简化数据输入工具：&lt;/strong> 开发像 Gitingest 和 DeepWiKI这样的小工具，通过改变URL就能让GitHub仓库、文档等内容对LLM可用，从而解锁大量使用场景。&lt;/li>
&lt;/ul>
&lt;p>Karpathy还以自动驾驶为例，指出从完美演示到大规模落地需要漫长的时间。他认为，AI代理的全面普及将是一个“代理的十年”，我们需要保持谨慎，避免过度兴奋，并强调“&lt;strong>钢铁侠战衣&lt;/strong>”的类比——我们需要构建的是增强和托尼·斯塔克结合的“部分自主产品”，而不是完全自主的炫酷演示。这种产品能够让“人机生成-验证循环”快速运转，并随着时间推移，通过调整自主度滑块，逐步实现更高程度的自动化。&lt;/p>
&lt;h3 id="总结与展望">总结与展望&lt;/h3>
&lt;p>Karpathy的演讲描绘了一个充满变革和机遇的时代。软件的本质正在被重塑，编程变得更加普适，LLMs作为新的计算基础设施，既带来了超能力，也伴随着独特的缺陷。我们面临着重写大量代码的挑战，但同时也拥有为数字信息操纵者构建全新软件的巨大机会。&lt;/p>
&lt;p>这是一个进入软件行业的绝佳时机，未来十年，我们将共同见证并参与构建更加智能、部分自主的软件产品，它们将像“钢铁侠战衣”一样，在增强人类能力的同时，逐步实现更高程度的自动化。&lt;/p>
&lt;p>你认为，在未来的软件开发中，人与AI的协作模式将如何演变？&lt;/p>
&lt;h3>&lt;/h3>
&lt;p>&lt;strong>欢迎关注+点赞+推荐+转发&lt;/strong>&lt;/p></description></item></channel></rss>